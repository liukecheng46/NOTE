# 多线程与并发

![Untitled](多线程与并发/Untitled.png)

什么是进程和线程？

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 思索

线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程 

进程是资源分配的最小单位，线程是系统调度的最小单位

**进程切换涉及虚拟地址空间的切换而线程不会。进程线程的切换涉及到内核的任务调度，所以一定切换到内核态**

线程崩溃一般是资源同步失败或者干脆就没同步造成的内存访问/读写错误

**线程崩溃进程会崩溃吗**？

这个要分情况，java jvm的线程是在用户态下的（jvm线程和内核线程一对一），线程崩溃不会导致进程崩溃，但是对于linux这种线程是在内核态下的，会导致进程崩溃。用户线程和内核线程可以是多对一，多对多，一对一的，**hotspot的用户线程和内核线程是一对一的**

划分用户态和内核态就是为了避免对操作系统运行造成威胁。

- 内核空间（Kernal Space），这个空间只有内核程序可以访问；
- 用户空间（User Space），这部分内存专门给应用程序使用。

用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在**用户态（User Mode）** 执行。内核空间中的代码可以访问所有内存，我们称这些程序在**内核态（Kernal Mode）** 执行。

![Untitled](多线程与并发/Untitled%201.png)

**为什么要隔离用户态和内核态**？

通过区分内核空间和用户空间的设计，**隔离了操作系统代码(操作系统的代码要比应用程序的代码健壮很多)与应用程序代码。**

**即便是单个应用程序出现错误也不会影响到操作系统的稳定性，这样其它的程序还可以正常的运行**

协程：协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。**协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程**，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多（java本身没有实现协程，有三方库）

并发和并行：并发的关键是你有处理多个任务的能力，不一定要同时（cpu交替）。并行的关键是你有同时处理多个任务的能力

JMM是一种规范，**屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致的并发效果。**

Java内存模型规定**所有的变量都存储在主内存**中，包括实例变量，静态变量，但是不包括局部变量和方法参数。每个线程都有自己的工作内存，**线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行**。**线程不能直接读写主内存中的变量**。

不同的线程之间也无法访问对方工作内存中的变量。线程之间变量值的传递均需要通过主内存来完成。

![Untitled](多线程与并发/Untitled%202.png)

线程安全（也是**JMM**）的特性：**原子性 有序性 可见性**

1、原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。

2、可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile 就是负责保证可见性的。

3、有序性，是保证线程内串行语义，避免指令重排等。

JMM内存模型和Java的并发编程有关是和多线程相关的一组规范，需要各个JVM实现遵守JMM规范，便于开发者利用规范开发多线程程序，以便于统一程序在不同平台运行得到结果相同。与处理器、缓存、并发、编译器有关，解决了CPU多级缓存、处理器优化、指令重排等结果不可预期的原理。volatile、synchronized、final、Lock等在JMM帮助下翻译出合适指令

线程的生命周期：

waiting和time_waiting分别是wait()和sleep()调用后进入的状态

![Untitled](多线程与并发/Untitled%203.png)

![Untitled](多线程与并发/Untitled%204.png)

什么是上下文切换：线程切换意味着保存当前线程的程序计数器，栈信息。留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的上下文切换

使用线程的方法：

- 实现 Runnable 接口；
- 实现 Callable 接口；
- 继承 Thread 类。

前面两种方法只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用

### **实现 Runnable 接口**

需要实现 run() 方法。

通过 Thread 调用 start() 方法来启动线程。

![Untitled](多线程与并发/Untitled%205.png)

### **实现 Callable 接口**

与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。

![Untitled](多线程与并发/Untitled%206.png)

### 继承 Thread 类

同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。

当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。

![Untitled](多线程与并发/Untitled%207.png)

实现接口的方法好一些，因为继承了 Thread 类就无法继承其它类，但是可以实现多个接口，并且继承整个 Thread 类可能没必要，开销过大

****我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？****

new 一个 Thread，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `**start()` 会执行线程的相应准备工作**，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 `start()` 方法方可启动线程并使线程进入就绪状态等待被调用，直接执行 `run()` 方法的话不会以多线程的方式执行。**

**线程池Executor**：

提高线程利用率，降低创建和销毁线程的消耗。提高响应速度；任务来了，直接有线程可用可执行，而不是先创建线程，再执行。提高线程的可管理性；线程是稀缺资源，使用线程池可以统一分配调优监控

管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。

CachedThreadPool: 一个任务创建一个线程； 

FixedThreadPool: 所有任务只能使用固定大小的线程；

SingleThreadExecutor: 相当于大小为 1 的 FixedThreadPool。

```java
public static void main(String[] args) {
    ExecutorService executorService = Executors.newCachedThreadPool();
    for (int i = 0; i < 5; i++) {
        executorService.execute(new MyRunnable());
    }
    executorService.shutdown();
}
```

阿里巴巴java开发手册中线程池不允许使用 Executors 去创建，而是通过 **ThreadPoolExecutor自定义创建** 的方式，这样的处理方式让写的同学更加**明确线程池的运行规则，规避资源耗尽的风险**。因为**Executors线程池允许Intger.MAX_Value的请求队列长度和允许创建的线程数量，都可能会导致OOM**。

**`ThreadPoolExecutor`的核心参数：**

- **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- keey-alive时间：多余空闲线程数的存活时间，当前线程数大于corePoolSize，并且等待时间大于keepAliveTime，多于线程或被销毁直到剩下corePoolSize为止
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。是需要传入具体的阻塞队列并定义好大小。
- ThreadFactory：线程工厂，用来生产线程执行任务。我们可以选择使用默认的创建工厂，产生的线程都在同一个组内，拥有相同的优先级，且都不是守护线程。当然我们也可以选择 自定义线程工厂，一般我们会根据业务来制定不同的线程工厂
- handler：拒绝策略，当堵塞队列满了并且工作线程大于线程池的最大线程数（maximumPoolSize）

**有哪些拒绝策略**：

1.ThreadPoolExecutor.AbortPolicy

线程池的**默认拒绝策略**为AbortPolicy，即丢弃任务并抛出RejectedExecutionException异常（即后面提交的请求不会放入队列也不会直接消费**并抛出异常**）；

2.ThreadPoolExecutor.DiscardPolicy

丢弃任务，但是不抛出异常。如果线程队列已满，则后续提交的任务都会被丢弃，且是静默丢弃（也不会抛出任何异常，任务直接就丢弃了）。

3.ThreadPoolExecutor.DiscardOldestPolicy

丢弃队列最前面的任务，然后重新提交被拒绝的任务（丢弃掉了队列最前的任务，并不抛出异常，直接丢弃了）。

4.ThreadPoolExecutor.CallerRunsPolicy

由调用线程处理该任务（不会丢弃任务，最后所有的任务都执行了，并不会抛出异常）

**为什么要用阻塞队列**：

一般的队列只能保证作为一个有限长度的缓冲区，如果超出了缓冲长度，就无法保留当前的任务 了，**阻塞队列通过阻塞可以保留住当前想要继续入队的任务**。

**阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程，使得线程进入wait状态，释放cpu资源**。

阻塞队列自带阻塞和唤醒的功能，不需要额外处理，无任务执行时,线程池利用阻塞队列的take方法挂起，从而维持核心线程的存活、不至于一直占用cpu资源

在创建新线程的时候，是要获取全局锁的，这个时候其它的就得阻塞，影响了整体效率（所以有corepoolsize和maxiumpoolsize）

****线程池的参数如何确定****

一般需要确定核心线程数、最大线程数、任务队列和拒绝策略，这些需要根据实际的业务场景去设置，可以大致分为CPU密集型和IO密集型。

CPU密集型时，只有多核cpu才能有提升，在单核CPU上，无论你开几个模拟的多线程，该任务都不可能得到加速，因为CPU总的运算能力就那些。**任务可以少配置线程数，大概和机器的cpu核数相当，这样可以使得每个线程都在执行任务**。

IO密集型时，**大部分线程都阻塞，故需要多配置线程数**，2*cpu核数。加速主要就是利用了被浪费掉的阻塞时间

常用的为**无界队列**为LinkedBlockingQueue，使用该队列做为阻塞队列时要尤其当心，当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM

一类是遵循FIFO原则的队列如ArrayBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐

![Untitled](多线程与并发/Untitled%208.png)

线程池的execute调用了如下步骤：

首先判断当前线程池中执行的任务数量是否小于 corePoolSize，如果小于的话，通过addWorker(command, true)新建一个线程，并启动该线程开始任务。

举例：

代码中模拟了 10 个任务，我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的5个任务中如果有任务被执行完了，线程池就会去拿新的任务执行。

![Untitled](多线程与并发/Untitled%209.png)

线程池的线程复用就是通过**取 Worker 的 firstTask 或者通过 getTask 方法从 workQueue 中不停地取任务**，并直接调用 Runnable 的 run 方法来执行任务，这样就保证了每个线程都始终在一个循环中，反复获取任务，然后执行任务，从而实现了线程的复用。

其核心原理在于线程池对Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程去执行一个while循环，在这个循环中不停检查是否有任务需要被执行，如果有则直接执行，也就是调用传入任务中的 run 方法，将 run 方法当成一个普通的方法执行，通过这种方式只使用固定的线程就将所有任务的 run 方法串联起来

**守护线程Daemon**：

守护线程是**程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分**。

当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。**main() 属于非守护线程**。使用 setDaemon() 方法将一个线程设置为守护线程。

GC线程属于一个典型的守护线程

```java
public static void main(String[] args) {
    Thread thread = new Thread(new MyRunnable());
    thread.setDaemon(true);
}
```

**Thread.yield()静态方法**：声明了当前线程已经完成了生命周期中最重要的部分，**可以切换给其它线程来执行。该方法只是对线程调度器的一个建议**，而且也只是建议具有相同优先级的其它线程可以运行。

```java
public void run() {
		// do something

    Thread.yield();
}
```

**Thread.Interrupt()中断方法**，通知线程应该中断了，具体到底中断还是继续运行，由被通知的线程自己处理。

当对一个线程，调用 interrupt() 时，

① 如果线程处于被阻塞状态（例如处于sleep, wait, join 等状态），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常，但是不能中断 I/O 阻塞和 synchronized 锁阻塞

② 如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。

通过interrupt()和.interrupted()方法两者的配合可以实现正常去停止一个线程，线程A通过调用线程B的interrupt方法通知线程B让它结束线程，在线程B的run方法内部，通过循环检查.interrupted()方法是否为真来接收线程A的信号，如果为真就可以抛出一个异常，在catch中完成一些清理工作，然后结束线程。Thread.interrupted()会清除标志位，并不是代表线程又恢复了，可以理解为仅仅是代表它已经响应完了这个中断信号然后又重新置为可以再次接收信号的状态。从始至终，理解一个关键点，interrupt()方法仅仅是改变一个标志位的值而已，和线程的状态并没有必然的联系

死锁的四个必要条件：

- 互斥条件：该资源任意一个时刻只由一个线程占用。
- **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不被剥夺:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
- 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

**安全状态** 指的是系统能够按照某种进程推进顺序（P1、P2、P3.....Pn）来为每个进程分配所需资源，直到满足每个进程对资源的最大需求，使每个进程都可顺利完成。称<P1、P2、P3.....Pn>序列为安全序列。

线程间的协作：多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。

Join（）方法：在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。

![Untitled](多线程与并发/Untitled%2010.png)

****wait() notify() notifyAll()方法：****

调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。

它们都属于 Object 的一部分，而不属于 Thread。

只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。

使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。

**await() signal() signalAll()方法：**

java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。

睡眠和挂起：线程的****sleep() 方法和Object的 wait() 方法区别和共同点：****

- 两者最主要的区别在于：**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了同步资源锁** 。只有再次调用notify()方法，之前调用过wait()的线程才会解除wait状态，再次有资格参与竞争同步资源锁
- 两者都可以暂停线程的执行。
- sleep可以用在任何地方，但是wait只能在同步方法或同步块(synchronized)中使用
- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

线程互斥同步机制：

提供了两种锁机制，一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock

### synchronized关键字详解：

![Untitled](多线程与并发/Untitled%2011.png)

1.**Synchronized可以作用在哪里，分别通过对象锁和类锁进行举例**。

修饰普通代码块，方法： 每个实例对象一把锁

修饰类，静态方法：这个类的所有对象共用一把锁

2**.Synchronized同步原理：对象监视器monitor（又叫管程）**

[https://segmentfault.com/a/1190000016417017](https://segmentfault.com/a/1190000016417017)

反编译Class文件可以看到，同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。

进入同步代码时线程试图获取锁也就是获取被锁对象的 **对象监视器 `monitor`**的持有权（Java 虚拟机HotSpot中，**Monitor 底层（Object Monitor）是基于 C++实现的（调用操作系统的互斥原语mutex来实现,被阻塞的线程会被挂起、等待重新调度,会导致用户态和内核态两个态之间来回切换，所以是重量级锁）**，**每个对象中都隐式内置了一个 `Monitor`对象（**但monitor并不是随着对象创建而创建的。我们是通过synchronized修饰符告诉JVM需要为我们的某个对象创建关联的monitor对象**）**；`**wait/notify`等方法也依赖于`monitor`**，这就是为什么**只有在同步的块或者方法中才能调用`wait/notify`** 等方法）如果Monitor锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器加 1，如果已经拿到了锁又重入了这把锁，则继续加1。（**Synchronized属于可重入锁-外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码**）

每个对象都有自己的一个monitor监视器对象，如果线程没有获得对象监视器，就会处于阻塞状态

在执行 `monitorexit`指令后，将锁计数器减一，减完不是0，代表刚才是重入进来的，还继续持有该锁，如果减完变成0了，锁被释放，其他线程可以尝试获取锁。

synchronized **修饰的方法并没有 monitorenter 指令和 monitorexit 指令**，取得代之的确实是ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。**不过两者的本质都是对对象监视器 monitor 的获取。**如果是基于对Obejct的monitor实现加锁，那synchronized对方法加锁是怎么实现的呢？如果修饰的是实例方法，那么其关联的对象实际上是 this，如果修饰的是类方法，那么其关联的对象是 this.class

ObjectMonitor机制（底层是c++实现的）包括了wait/notify方法，具体的就是可以调用wait让当前线程释放锁，并进入wait set，当再次调用notify方法时才会进入entry set。entry和wait set是objectmonitor的两个成员变量（链表）

监控区（Entry Set）：锁已被其他线程获取，期待获取锁的线程就进入Monitor对象的监控区

待授权区（Wait Set）：曾经获取到锁，但是调用了wait方法，线程进入待授权区

- 所有期待获得锁的线程，在锁已经被其它线程拥有的时候，这些期待获得锁的线程就进入了对象锁的`entry set`区域。
- 所有曾经获得过锁，但是由于其它必要条件不满足而需要wait的时候，线程就进入了对象锁的`wait set`区域 。
- 在`wait set`区域的线程获得`Notify/notifyAll`通知的时候，随机的一个`Thread（Notify）`或者是全部的`Thread（NotifyALL）`从对象锁的`wait set`区域进入了`entry set`中。
- 在当前拥有锁的线程释放掉锁的时候，处于该对象锁的`entryset`区域的线程都会抢占该锁，但是只能有任意的一个Thread能取得该锁，而其他线程依然在`entry set`中等待下次来抢占到锁之后再执行

.**构造方法不能使用 synchronized 关键字修饰。**

构造方法本身就属于线程安全的，不存在同步的构造方法一说

4.JDK对****synchronized关键字底层做了什么优化？现在各个框架源码都大量使用它****

 JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。锁主要存在四种状态，依次是：**无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态**，他们会随着竞争的激烈而逐渐升级。注意**锁可以升级不可降级**，这种策略是为了提高获得锁和释放锁的效率。

`锁粗化(Lock Coarsening)`：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。 按理来说，同步块的作用范围应该尽可能小，仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，缩短阻塞时间，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。但是加锁解锁也需要消耗资源，如果存在一个线程一系列的连续加锁解锁操作，甚至加锁操作是出现在循环体中的，可能会导致不必要的性能损耗。

`锁消除(Lock Elimination)`：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配(同时还可以减少Heap上的垃圾收集开销)。 

`轻量级锁(Lightweight Locking)`：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。 

`偏向锁(Biased Locking)`：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 

自适应自旋`(Adaptive Spinning)`：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态。

**自旋锁与自适应自旋锁**：

在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，**共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间**。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程**执行一个忙循环(自旋)**，这便是自旋锁由来的原因。

但是自旋锁的时间是固定设置的，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果**锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源**)。因此自旋等待的时间必须要有一定的限度，如果**自选超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了**。还引入了自适应自旋锁，**自旋的时间不再固定了，而是由前一次在同一个锁上的自旋 时间及锁的拥有者的状态来决定的**。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。**有了自适应自旋，JVM对程序的锁的状态预测会越来越准确**

**锁消除**：在JVM里的逃逸分析就讲到了，JVM会自动优化一些认为不会存在共享数据竞争的锁和同步代码块，把它们当作栈上数据对待，认为这些数据时线程独有的，不需要加同步。此时就会进行锁消除

****锁粗化：****如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要地性能操作

```java
public static String test04(String s1, String s2, String s3) {
    StringBuilder sb = new StringBuilder();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
```

在上述地连续append()操作中就属于这类情况。JVM会检测到这样一连串地操作都是对同一个对象加锁，那么JVM会将加锁同步地范围扩展(粗化)到整个一系列操作的 外部，使整个一连串地append()操作只需要加锁一次就可以了

对象在内存中分为三块区域：

- 对象头：**标记字段**和**类型指针**。
- 实例数据：这部分主要是存放类的数据信息，父类的信息。
- 对齐填充：由于**虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐（提高效率，假如要读8字节的数据，不对齐可能要读两次-可能被放在了两个8bytes的内存块）**。

每个对象都有一个对象头，期中有一个主要区域叫mark word里面保存了一些必要的数据信息，其中与锁机制相关的有如下标志

![Untitled](多线程与并发/Untitled%2012.png)

[https://blog.csdn.net/yinwenjie/article/details/84922958](https://blog.csdn.net/yinwenjie/article/details/84922958)

[https://cloud.tencent.com/developer/article/1403960](https://cloud.tencent.com/developer/article/1403960)

[https://blog.csdn.net/hancoder/article/details/120421993](https://blog.csdn.net/hancoder/article/details/120421993)

(mark word不等于对象头，Mark word是对象头中的一部分，不过在下文，可以把对象头和mark word看作是一个东西)

**重量级锁**：mutex互斥锁机制，在java中就是通过monitor对象和objectMonitor机制实现的，**获得锁后会将被锁关联对象的mark down指向重量级锁（monitor对象）的指针**

****轻量级锁: 是一种乐观锁，基于CAS+锁自旋，****对在大多数情况下同步块并不会有竞争出现提出的一种优化。利用CAS操作替换重量级锁，减少对线程的阻塞带来地线程开销。从而提高并发性能。

首先判断当前对象没有被锁定（标记位不是00），锁标志位为01状态，如果无锁，**会在当前线程栈帧中创建锁记录的空间并存储锁对象的mark down的拷贝（不是引用）**。然后，**虚拟机使用CAS操作将被加锁对象的`Mark Word`（不包括后两位的标志位）尝试更新为指向该线程之前拷贝的Mark down信息（线程的锁记录）的指针。如果更新成功了，那么这个线程就拥有了该对象的锁**，并且对象Mark Word的锁标志位更新为00，即表示此对象处于轻量级锁定状态

如果这个CAS更新操作失败，JVM会检查当前线程`Mark Word`中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，**如果自旋等待超过一定次数或者有两条以上（重点）的线程竞争同一个锁，那轻量级锁就不再有效**，**直接膨胀位重量级锁-**没有获得锁的线程会被阻塞

![Untitled](多线程与并发/Untitled%2013.png)

 轻量级解锁时，会使用CAS操作将自己线程栈中复制的`Mark Word` （**包括后两位的标志位，用这个来判断**）替换回到对象头中，如果成功，则表示没有发生竞争关系，如果失败了，说明有其他线程尝试获取该锁（标志位被别人改为重量级锁的标志`10`了），轻量级锁膨胀升级为重量级锁

**若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁**。

**总结就是通过CAS操作和锁自旋，使得多个线程竞争同步资源时，没有获取到资源的线程自旋等待锁释放，而不会阻塞**。

****偏向锁：****锁**不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，轻量级锁的CAS操作在这种情况也变得”重”了**，因此引入偏向锁

当一个线程访问同步快并获取锁时，会**在锁关联对象的对象头的mard word和栈帧中的锁记录里存储锁偏向的线程ID**，以后该线程在进入和推出同步块时不需要进行CAS操作来加锁和解锁。**只需要简单地测试一下对象头的`Mark Word`里是否存储着指向当前线程的偏向锁**。如果成功，表示线程已经获取到了锁。

偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时持有偏向锁的线程才会释放锁。但是**偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着（所以偏向锁的缺点在于锁撤销的消耗）**。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁

同一个线程执行同步资源时自动获取资源，**当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁**

举例：

当前进程中只有线程A在请求同步代码块X的对象操作权（对象记为Y），这时synchronized控制机制就会将Y对象的对象头记为“偏向锁”。这时线程A依然在执行同步代码块X时，又有另一个线程B试图抢占对象Y的操作权。如果线程B通过“自旋”操作等待后依然没有获取到对象Y的操作权，则锁升级为轻量级锁

![Untitled](多线程与并发/Untitled%2014.png)

1. Synchronied同步锁的类型：

无锁（自旋锁） → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的，锁可以升级但是不可以降级，目的是**为了提高获取锁和释放锁的效率**。)

6.****synchronized和Lock类（ReentrantLock）的对比，如何选择？****

ReentrantLock是Lock的实现类，两者性能差不多，ReentrantLock是**轻量级锁，基于AQS**。**采用cas+volatile管理线程**，不需要线程切换

ReentrantLock**必须手动获取与释放锁**，****ReentrantLock****只适用于代码块锁

synchronized和ReentrantLock都是可重入锁，指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁

synchronized是JVM层面实现的，ReentrantLock是JDK层面代码实现的。reentrantLock底层通过Lock获取的锁也是基于监视器的锁，不过他们两所持有的对象监视器不同（？）

ReentrantLock相比synchronized多了一些高级功能：

- **等待可中断** : `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的**公平锁就是先等待的线程先获得锁**。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
- **可实现选择性通知（ReentrantLock锁可以同时绑定多个条件）**: `synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。**而且是可选择性通知，notify()方法进行通知时，被通知的线程是Java虚拟机随机选择的，但ReentrantLock结合Condition可以实现有选择性地通知，Condition和Lock是绑定的**

ReentrantLock适用于时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者锁投票等synchronized无法提供的功能场景

![Untitled](多线程与并发/Untitled%2015.png)

**ReentrantLock分析**：

实现了Lock接口。内部存在如下三个类

![Untitled](多线程与并发/Untitled%2016.png)

****volatile关键字：****

![Untitled](多线程与并发/Untitled%2017.png)

1**.volatile关键字有什么作用？**

防止指令重排序，保证可见性和一定的有序性

2.**volatile能保证原子性吗**

volatile变量不能保证完全的原子性，只能保证**单次的读/写操作具有原子性**

如i++不能保证原子性，因为这个操作本质上是读+写两次操作

3.**volatile的实现原理**

volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现

内存屏障，又称内存栅栏，是一个 **CPU 指令**。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，**插入一条内存屏障（Lock指令）会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序**

被volatile修饰的变量会有一个**lock汇编指令**，**lock 前缀**的指令在多核处理器下会引发两件事情:

- 将当前处理器缓存行的数据写回到系统内存。
- 写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。
- 

（1）对于写操作：对变量更改完之后，要立刻写回到主存中：向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。

（2）对于读操作：对变量读取的时候，要从主存中读，而不是缓存。当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。

**as-if-serial规则和happens-before规则的区别？**

区别：

- as-if-serial定义：无论编译器和处理器如何进行重[排序](https://www.notion.so/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F)，单线程程序的执行结果不会改变。
- happens-before定义：一个操作happens-before另一个操作，**表示第一个的操作结果对第二个操作可见**，并且第一个操作的执行顺序也在第二个操作之前。**但这并不意味着Java虚拟机必须按照这个顺序来执行程序。如果重[排序](https://www.notion.so/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F)的后的执行结果与按happens-before关系执行的结果一致**，Java虚拟机也会允许重[排序](https://www.notion.so/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F)的发生。
- happens-before关系保证了同步的多线程程序的执行结果不被改变，as-if-serial保证了单线程内程序的执行结果不被改变。

相同点：**happens-before和as-if-serial的作用都是在不改变程序执行结果的前提下，提高程序执行的并行度。**

重排序通过减少执行指令，从而提高整体的运行速度

10个线程对加volatile的变量加10次，最后结果是100吗？

多线程环境下，有可能线程A将num读取到本地内存中，此时其他线程可能已经将num增大了很多，线程A依然对过期的num进行自加，重新写到主存中，最终导致了num的结果不合预期，而是小于100

ThreadLocal**关键字：**

![Untitled](多线程与并发/Untitled%2018.png)

如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK 中提供的ThreadLocal类正是为了解决这样的问题。ThreadLocal是一个将在多线程中为每一个线程创建单独的变量副本的类; 当使用ThreadLocal来维护变量时, ThreadLocal会为每个线程创建单独的变量副本, 避免因多线程操作共享变量而导致的数据不一致的情况

ThreadLocal 线程隔离：

Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap，每个线程都有一个独立的ThreadLocalMap，**key为ThreadLocal**的实例，value为这个ThreadLocal保存的对象

![Untitled](多线程与并发/Untitled%2019.png)

****ThreadLocal 内存泄露问题：弱引用****

ThreadLocalMap 中使用的 **key 为 ThreadLocal 的弱引用**,而 value 是强引用。所以，如果 **ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉**。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收 

ThreadLocalMap 实现中已经考虑了这种情况，**在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录**。使用完 ThreadLocal方法后 要**手动调用remove()方法**

为什么要是弱引用：如果是强引用的话，即使ThreadLocal的值是为null，但是的话ThreadLocalMap还是会有ThreadLocal的强引用状态，如果没有手动进行删除的话，ThreadLocal就不会被回收，这样就会导致Entry内存的泄漏（map的生命周期和线程相同，所以如果线程池的话，那就一直不会被回收）

使用场景：作用在每个线程内都都需要独立的保存信息，这样就方便同一个线程的其他方法获取到该信息的场景，并且这些变量是和线程的生命周期密切相关的，线程结束，变量也就销毁了。

ThreadLocal 不是为了解决线程间的共享变量问题的，如果是多线程都需要访问的数据，那需要用全局变量加同步机制

```java
#用户微服务配置token解密信息传递例子
public static ThreadLocal<LoginUser> threadLocal = new ThreadLocal<>();
                LoginUser loginUser = new LoginUser();
                loginUser.setId(id);
                loginUser.setName(name);
                loginUser.setMail(mail);
                loginUser.setHeadImg(headImg);
                threadLocal.set(loginUser);
            
后续想直接获取到直接threadLocal.getxxx就可以了
```

全局存储用户信息：我们会选择在拦截器的业务中， 获取到保存的用户信息，然后存入ThreadLocal，那么当前线程在任何地方如果需要拿到用户信息都可以使用ThreadLocal的get()方法 (异步程序中ThreadLocal是不可靠的)

线程池里不要用ThreadLocal，因为线程池里对线程的管理都是线程复用的方法，所以在线程池里线程非常难结束，更有可能的是永远不会结束

**异步程序也不要用ThreadLocal来传递参数**，由于线程将请求发送后。就不再等待远程返回结果继续向下运行了，**真正的返回结果得到后，处理的线程可能是其他的线程**。Java8中的并发流也要考虑这种情况

### **CAS和Aotimc类**

![Untitled](多线程与并发/Untitled%2020.png)

1.**线程安全的实现方法有哪些**？

互斥同步的有synchronized和Reentrantlock锁

无同步方案有ThreadLocal和栈封闭

还有**非阻塞同步的CAS和AtomicXXX**

2.**什么是CAS**

CAS的全称为Compare-And-Swap，直译就是对比交换。是一条**CPU的原子指令**，其作用是让CPU先进行比较预期值和真实值是否相等，然后原子地更新某个位置的值，其实现方式是**基于硬件平台的汇编指令，就是说CAS是靠硬件实现的**，JVM只是封装了汇编调用

CAS(V,A,E): V表示要更新变量在内存中的当前值，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程则什么都不做

简单解释就是 CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先**比较下旧值有没有发生变化**，如果没有发生变化，才交换成新值，发生了变化则不交换。

**CAS操作是原子性的**，所以多线程并发使用CAS更新数据时，可以不使用锁。JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。

而AtomicXXX类就是基于JVM封装的这些CAS汇编调用接口而写的，比如AtomicIntegr类（基于CAS进行数据更新），不需要加锁就可以在多线程下实现数据的一致性

```java
public class Test {
    private  AtomicInteger i = new AtomicInteger(0);
    public int add(){
        return i.addAndGet(1);
    }
}
```

3.**乐观锁和悲观锁**

CAS为乐观锁（认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作），而synchronized和Rentrantlock为悲观锁（认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改）

4.**CAS会带来什么问题？**

（1）ABA问题. CAS需要在操作值的时候，检查值有没有发生变化，比如没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时则会发现它的值没有发生变化，但是实际上却变化了。**ABA问题的解决思路就是使用版本号**。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A。

JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且**检查当前版本号是否等于预期版本号**，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值，内部使用Pair来存储元素值及其版本号

（2）循环时间长开销大：**CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销**

（3）只能保证一个共享变量的原子操作：

对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

- Java从1.5开始JDK**提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作**。
- 把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i = 2，j = a，合并一下ij = 2a，然后用CAS来操作ij

5.**AtomicInteger类的底层实现和源码分析**：

使用Unsafe库中**封装的CAS方法以及Volatile**修饰int value值来实现的线程安全三特性

![Untitled](多线程与并发/Untitled%2021.png)

除了原子更新基本类型，还提供了原子更新数组和原子更新引用类型，原子更新字段类

原子更新引用类型：

AtomicReference: 原子更新引用类型。 

AtomicStampedReference: 原子更新引用类型, 内部使用Pair来存储元素值及其版本号。 

AtomicMarkableReferce: 原子更新带有标记位的引用类型。

### **Fork/Join**

java7提供的一个用于并行执行任务的框架，把一个大任务分割成若干个小任务，最终汇总每个小任务结果的后得到大任务结果的框架

### **锁核心类AQS：**

![Untitled](多线程与并发/Untitled%2022.png)

1.什么是AQS？为什么它是锁的核心部分

****AbstractQueuedSynchronizer，****是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出大量应用广泛的同步器，比如我们提到的**ReentrantLock**，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。它的核心思想是如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

![Untitled](多线程与并发/Untitled%2023.png)

AQS使用一个**volatile修饰的int成员变量**来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。AQS基于CAS操作+volatile对共享变量进行并发操作（只是进行state的并发更新，但是state为0时获取不到的线程还是会阻塞的，不是CAS+自旋）

```java
private volatile int state;//共享变量，使用volatile修饰保证线程可见性
```

AQS定义了两种资源共享方式：

- **Exclusive**（独占）：**只有一个线程能执行**，如 `ReentrantLock`。又可分为公平锁和非公平锁：
    - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
    - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的
- **Share**（共享）：**多个线程可同时执行**，如`CountDownLatch`、`Semaphore`、 `CyclicBarrier`、`ReadWriteLock`
- 

AQS实现了以下重要逻辑：

- **状态的原子性管理 （acquire和release）**
- **线程的阻塞与解除阻塞**
- **队列的管理**

AQS的三大核心就是状态，队列和期望实现类实现的获取/释放等重要方法

**状态**：

state 的含义并不是一成不变的，它会根据具体实现类的作用不同而表示不同的含义

在**Semaphore**里面，state 表示的是剩余许可证的数量

在 **CountDownLatch** 工具类里面，state 表示的是需要“倒数”的数量

在 **ReentrantLock** 中它表示的是锁的占有情况。最开始是 0，表示没有任何线程占有锁；如果 state 变成 1，则就代表这个锁已经被某一个线程所持有了。ReentrantLock 是可重入的，同一个线程可以再次拥有这把锁就叫重入。如果这个锁被同一个线程多次获取，那么 state 就会逐渐的往上加，state 的值表示重入的次数。
调用acruire方法时，如果为state0则没有获取到，当前线程将在AQS中进行排队，并且当前试图获取锁的线程将会继续阻塞

**FIFO队列**：

存储等待线程。多个线程同时争抢锁，大部分线程抢不到，AQS的FIFO队列负责充当“排队管理器” ，是一个双向链表。

**获取/释放 方法**

不同工具类实现各不相同。

获取 方法(通常都会与state相关)

- ReentrantLock中lock:state不为0且当前线程不是持有锁的线程，代表锁被其他线程持有，让该线程进入阻塞状态。
- Semaphore中的acquire方法是获取许可证，取决于state,state>0说明有剩余许可证，数量足够可以获取；state=0，说明没有许可证，进入阻塞状态。
- CountDownLatch的await方法。作用是等待，直到倒数结束，state!=0线程就阻塞，state=0门闩放开，阻塞线程会被唤醒

释放 方法

与获取方法相反，通常是让state数扣减，贴近0，

CountDownLatch：一个线程或多个等待另外n个线程完成之后才能执行

在构造CountDownLatch的时候需要传入一个整数n，在这个整数“倒数”到0之前，主线程需要等待在门口，而这个“倒数”过程则是由各个执行线程驱动的，每个线程执行完一个任务“倒数”一次。总结来说，CountDownLatch的作用就是等待其他的线程都执行完任务，必要时可以对各个任务的执行结果进行汇总，然后主线程才继续往下执行。

CountDownLatch主要有两个方法：countDown()和await()。countDown()方法用于使计数器减一，其一般是执行任务的线程调用，await()方法则使调用该方法的线程处于等待状态，其一般是主线程调用

我们要读取处理 6 个文件，这 6 个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理。

为此我们定义了一个线程池和 count 为 6 的`CountDownLatch`对象 。使用线程池处理读取任务，每一个线程处理完之后就将 count-1，调用`CountDownLatch`对象的 `await()`方法，直到所有文件读取完之后，才会接着执行后面的逻辑。

```java
public class CountDownLatchExample1 {
    // 处理文件的数量
    private static final int threadCount = 6;

    public static void main(String[] args) throws InterruptedException {
        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {
                try {
                    //处理文件的业务操作
                    //......
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    //表示一个文件已经被完成
                    countDownLatch.countDown();
                }

            });
        }
        countDownLatch.await();
        threadPool.shutdown();
        System.out.println("finish");
    }
}
```

`CyclicBarrier`: n个线程相互等待，任何一个线程完成之前，所有的线程都必须等待

让一组线程到达一个屏障（也可以叫同步点）时被阻塞，**直到最后一个线程到达屏障时，屏障才会开门**，所有被屏障拦截的线程才会继续运行。

CyclicBarrier默认构造放时CyclicBarrier(int parities) ,其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达屏障，然后当前线程被阻塞。

`Semaphore`:用来控制同时访问资源的线程数量，通过协调各个线程，来保证合理的公共资源的访问(有点像固定的令牌桶限流，初始令牌个数，桶里有令牌那这个线程就可以访问资源，访问完再把令牌扔回去)

**JUC的并发容器**：

****ConcurrentHashMap：****和HashTable的区别在于不是使用synchronized而是用分段锁，所以性能更快

****CopyOnWriteArrayList：****读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 `List` 的内部数据，毕竟读取操作是安全的。并且写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待

读取操作没有任何同步控制和锁操作，理由就是内部数组 `array` 不会发生修改，只会被另外一个 `array`替换，因此可以保证数据安全。

使用fail-safe机制****，****在写操作时（加锁），先将当前容器复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器

发现在添加的时候是需要加锁的，否则多线程写的时候会复制出N个副本出来……

读的时候不需要加锁，如果读的时候有多个线程正在向ArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的ArrayList。

CopyOnWrite的应用场景：CopyOnWrite并发容器用于**读多写少的并发场景**。比如白名单，黑名单，商品类目的访问和更新场景。

缺点：写时复制的机制会导致每次写都要复制内存，开销很大

数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的，所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。

**非阻塞队列 ConcurrentLinkedQueue**：既然是非阻塞，那么就是和CAS算法有关。适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 `ConcurrentLinkedQueue`
 来替代

**阻塞队列BlockingQueue：**ArrayBlockingQueue，LinkedBlockingQueue，PriorityBlockingQueue。**并发控制采用的是可重锁 `ReentrantLock`+condition**

**不管是插入操作还是读取操作，都需要获取到锁才能进行操作**

![Untitled](多线程与并发/Untitled%2024.png)

延迟队列：阻塞队列+优先级队列。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。队列中的Delayed必须实现compareTo来指定元素的顺序。比如让延时时间最长的放在队列的末尾