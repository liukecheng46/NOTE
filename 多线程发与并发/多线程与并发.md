# 多线程与并发

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled.png)

什么是进程和线程？

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 思索

线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程 

并发的关键是你有处理多个任务的能力，不一定要同时（cpu交替）。并行的关键是你有同时处理多个任务的能力

线程安全（也是JMM）的特性：

1、原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。

2、可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile 就是负责保证可见性的。

3、有序性，是保证线程内串行语义，避免指令重排等。

JMM内存模型和Java的并发编程有关是和多线程相关的一组规范，需要各个JVM实现遵守JMM规范，便于开发者利用规范开发多线程程序，以便于统一程序在不同平台运行得到结果相同。与处理器、缓存、并发、编译器有关，解决了CPU多级缓存、处理器优化、指令重排等结果不可预期的原理。volatile、synchronized、final、Lock等在JMM帮助下翻译出合适指令

线程的生命周期：

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%201.png)

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%202.png)

什么是上下文切换：线程切换意味着保存当前线程的程序计数器，栈信息。留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的上下文切换

使用线程的方法：

- 实现 Runnable 接口；
- 实现 Callable 接口；
- 继承 Thread 类。

前面两种方法只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用

### **实现 Runnable 接口**

需要实现 run() 方法。

通过 Thread 调用 start() 方法来启动线程。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%203.png)

### **实现 Callable 接口**

与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%204.png)

### 继承 Thread 类

同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。

当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%205.png)

实现接口的方法好一些，因为继承了 Thread 类就无法继承其它类，但是可以实现多个接口，并且继承整个 Thread 类可能没必要，开销过大

****我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？****

new 一个 Thread，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 `start()` 方法方可启动线程并使线程进入就绪状态等待被调用，直接执行 `run()` 方法的话不会以多线程的方式执行。**

**线程池Executor**：

管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。

CachedThreadPool: 一个任务创建一个线程； 

FixedThreadPool: 所有任务只能使用固定大小的线程；

SingleThreadExecutor: 相当于大小为 1 的 FixedThreadPool。

```java
public static void main(String[] args) {
    ExecutorService executorService = Executors.newCachedThreadPool();
    for (int i = 0; i < 5; i++) {
        executorService.execute(new MyRunnable());
    }
    executorService.shutdown();
}
```

阿里巴巴java开发手册中线程池不允许使用 Executors 去创建，而是通过 **ThreadPoolExecutor自定义创建** 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。因为Executors线程池允许Intger.MAX_Value的请求队列长度和允许创建的线程数量，都可能会导致OOM。

**`ThreadPoolExecutor`的核心参数：**

- **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%206.png)

线程池的execute调用了如下步骤：

首先判断当前线程池中执行的任务数量是否小于 corePoolSize，如果小于的话，通过addWorker(command, true)新建一个线程，并启动该线程开始任务。

举例：

代码中模拟了 10 个任务，我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的5个任务中如果有任务被执行完了，线程池就会去拿新的任务执行。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%207.png)

**守护线程Daemon**：

守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。

当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。main() 属于非守护线程。使用 setDaemon() 方法将一个线程设置为守护线程。

```java
public static void main(String[] args) {
    Thread thread = new Thread(new MyRunnable());
    thread.setDaemon(true);
}
```

Thread.yield()静态方法：声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。

```java
public void run() {
		// do something

    Thread.yield();
}
```

Thread.Interrupt()中断方法，通知线程应该中断了，具体到底中断还是继续运行，由被通知的线程自己处理。

当对一个线程，调用 interrupt() 时，

① 如果线程处于被阻塞状态（例如处于sleep, wait, join 等状态），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常，但是不能中断 I/O 阻塞和 synchronized 锁阻塞

② 如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。

通过interrupt()和.interrupted()方法两者的配合可以实现正常去停止一个线程，线程A通过调用线程B的interrupt方法通知线程B让它结束线程，在线程B的run方法内部，通过循环检查.interrupted()方法是否为真来接收线程A的信号，如果为真就可以抛出一个异常，在catch中完成一些清理工作，然后结束线程。Thread.interrupted()会清除标志位，并不是代表线程又恢复了，可以理解为仅仅是代表它已经响应完了这个中断信号然后又重新置为可以再次接收信号的状态。从始至终，理解一个关键点，interrupt()方法仅仅是改变一个标志位的值而已，和线程的状态并没有必然的联系

死锁的四个必要条件：

- 互斥条件：该资源任意一个时刻只由一个线程占用。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不被剥夺:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
- 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

**安全状态** 指的是系统能够按照某种进程推进顺序（P1、P2、P3.....Pn）来为每个进程分配所需资源，直到满足每个进程对资源的最大需求，使每个进程都可顺利完成。称<P1、P2、P3.....Pn>序列为安全序列。

线程间的协作：多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。

Join（）方法：在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%208.png)

****wait() notify() notifyAll()方法：****

调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。

它们都属于 Object 的一部分，而不属于 Thread。

只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。

使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。

**await() signal() signalAll()方法：**

java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。

睡眠和挂起：线程的****sleep() 方法和Object的 wait() 方法区别和共同点：****

- 两者最主要的区别在于：**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了同步资源锁** 。只有再次调用notify()方法，之前调用过wait()的线程才会解除wait状态，再次有资格参与竞争同步资源锁
- 两者都可以暂停线程的执行。
- sleep可以用在任何地方，但是wait只能在同步方法或同步块(synchronized)中使用
- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

线程互斥同步机制：

提供了两种锁机制，一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock

### synchronized关键字详解：

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%209.png)

1.**Synchronized可以作用在哪里，分别通过对象锁和类锁进行举例**。

修饰普通代码块，方法： 每个实例对象一把锁

修饰类，静态方法：这个类的所有对象共用一把锁

2**.Synchronized同步原理：**

反编译Class文件可以看到，同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。

进入同步代码时线程试图获取锁也就是获取 **对象监视器 `monitor`**的持有权（Java 虚拟机HotSpot中，Monitor 是基于 C++实现的，每个对象中都内置了一个 `ObjectMonitor`对象；`wait/notify`
等方法也依赖于`monitor`对象，这就是为什么只有在同步的块或者方法中才能调用`wait/notify`
等方法）如果Monitor锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器加 1，如果已经拿到了锁又重入了这把锁，则继续加1。（**Synchronized属于可重入锁**）

在执行 `monitorexit`指令后，将锁计数器减一，减完不是0，代表刚才是重入进来的，还继续持有该锁，如果减完变成0了，锁被释放，其他线程可以尝试获取锁。

synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。**不过两者的本质都是对对象监视器 monitor 的获取**

3.**构造方法不能使用 synchronized 关键字修饰。**

构造方法本身就属于线程安全的，不存在同步的构造方法一说

4.JDK对****synchronized关键字底层做了什么优化？现在各个框架源码都大量使用它****

 JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

`锁粗化(Lock Coarsening)`：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。 

`锁消除(Lock Elimination)`：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配(同时还可以减少Heap上的垃圾收集开销)。 

`轻量级锁(Lightweight Locking)`：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。 

`偏向锁(Biased Locking)`：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 

自适应自旋`(Adaptive Spinning)`：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态。

**自旋锁与自适应自旋锁**：

在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁由来的原因。

但是自旋锁的时间是固定设置的，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源)。因此自旋等待的时间必须要有一定的限度，如果自选超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了。还引入了自适应自旋锁，自旋的时间不再固定了，而是由前一次在同一个锁上的自旋 时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，JVM对程序的锁的状态预测会越来越准确

**锁消除**：在JVM里的逃逸分析就讲到了，JVM会自动优化一些认为不会存在共享数据竞争的锁和同步代码块，把它们当作栈上数据对待，认为这些数据时线程独有的，不需要加同步。此时就会进行锁消除

****锁粗化：****如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要地性能操作

```java
public static String test04(String s1, String s2, String s3) {
    StringBuilder sb = new StringBuilder();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
```

在上述地连续append()操作中就属于这类情况。JVM会检测到这样一连串地操作都是对同一个对象加锁，那么JVM会将加锁同步地范围扩展(粗化)到整个一系列操作的 外部，使整个一连串地append()操作只需要加锁一次就可以了

****轻量级锁:****对在大多数情况下同步块并不会有竞争出现提出的一种优化。它可以减少重量级锁对线程的阻塞带来地线程开销。从而提高并发性能。

如果当前对象没有被锁定，那么锁标志位位01状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录`Lock Record`的空间用于存储锁对象目前的`Mark Word`的拷贝。然后，虚拟机使用CAS操作将标记字段Mark Word拷贝到锁记录中，并且将`Mark Word`更新为指向`Lock Record`的指针。如果更新成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位更新为`Mark Word`中最后的2bit，即表示此对象处于轻量级锁定状态

如果这个更新操作失败，JVM会检查当前的`Mark Word`中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀位重量级锁，没有获得锁的线程会被阻塞

 轻量级解锁时，会使用原子的CAS操作将`Displaced Mark Word`替换回到对象头中，如果成功，则表示没有发生竞争关系。

若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。

总结就是通过CAS操作和锁自旋，使得多个线程竞争同步资源时，没有获取到资源的线程自旋等待锁释放，而不会阻塞。

****偏向锁：****锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争****，****轻量级锁的CAS操作在这种情况也变得”重”了，因此引入偏向锁

当一个线程访问同步快并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和推出同步块时不需要进行CAS操作来加锁和解锁。只需要简单地测试一下对象头的`Mark Word`里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。

偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时持有偏向锁的线程才会释放锁。但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁

同一个线程执行同步资源时自动获取资源，当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2010.png)

1. Synchronied同步锁的类型：

无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的，锁可以升级但是不可以降级，目的是为了提供获取锁和释放锁的效率。)

6.****synchronized和Lock类（ReentrantLock）的对比，如何选择？****

ReentrantLock是Lock的实现类，两者性能差不多，ReentrantLock是轻量级锁。**采用cas+volatile管理线程**，不需要线程切换切换

ReentrantLock必须手动获取与释放锁，****ReentrantLock****只适用于代码块锁

synchronized和ReentrantLock都是可重入锁，指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁

synchronized是JVM层面实现的，ReentrantLock是JDK层面代码实现的

ReentrantLock相比synchronized多了一些高级功能：

- **等待可中断** : `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
- **可实现选择性通知（ReentrantLock锁可以同时绑定多个条件）**: `synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。

ReentrantLock适用于时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者锁投票等synchronized无法提供的功能场景

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2011.png)

**ReentrantLock分析**：

实现了Lock接口。内部存在如下三个类

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2012.png)

****volatile关键字：****

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2013.png)

1**.volatile关键字有什么作用？**

防止指令重排序，保证可见性和一定的有序性

2.**volatile能保证原子性吗**

volatile变量不能保证完全的原子性，只能保证单次的读/写操作具有原子性

如i++不能保证原子性，因为这个操作本质上是读+写两次操作

3.**volatile的实现原理**

volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现

内存屏障，又称内存栅栏，是一个 CPU 指令。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，**插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序**

被volatile修饰的变量会有一个lock汇编指令，lock 前缀的指令在多核处理器下会引发两件事情:

- 将当前处理器缓存行的数据写回到系统内存。
- 写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。
- 

（1）对于写操作：对变量更改完之后，要立刻写回到主存中：向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。

（2）对于读操作：对变量读取的时候，要从主存中读，而不是缓存。当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。

ThreadLocal**关键字：**

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2014.png)

如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK 中提供的ThreadLocal类正是为了解决这样的问题。ThreadLocal是一个将在多线程中为每一个线程创建单独的变量副本的类; 当使用ThreadLocal来维护变量时, ThreadLocal会为每个线程创建单独的变量副本, 避免因多线程操作共享变量而导致的数据不一致的情况

ThreadLocal源码分析：

Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap，每个线程都有一个独立的ThreadLocalMap，key为ThreadLocal的实例，value为这个ThreadLocal保存的对象

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2015.png)

****ThreadLocal 内存泄露问题：****

ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收 

ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 要手动调用remove()方法

### **CAS和Aotimc类**

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2016.png)

1.**线程安全的实现方法有哪些**？

互斥同步的有synchronized和Reentrantlock锁

无同步方案有ThreadLocal和栈封闭

还有**非阻塞同步的CAS和AtomicXXX**

2.**什么是CAS**

CAS的全称为Compare-And-Swap，直译就是对比交换。是一条CPU的原子指令，其作用是让CPU先进行比较两个值是否相等，然后原子地更新某个位置的值，其实现方式是基于硬件平台的汇编指令，就是说CAS是靠硬件实现的，JVM只是封装了汇编调用

简单解释就是 CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较下旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。

CAS操作是原子性的，所以多线程并发使用CAS更新数据时，可以不使用锁。JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。

而AtomicXXX类就是基于JVM封装的这些CAS汇编调用接口而写的，比如AtomicIntegr类（基于CAS进行数据更新），不需要加锁就可以在多线程下实现数据的一致性

```java
public class Test {
    private  AtomicInteger i = new AtomicInteger(0);
    public int add(){
        return i.addAndGet(1);
    }
}
```

3.**乐观锁和悲观锁**

CAS为乐观锁（认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作），而synchronized和Rentrantlock为悲观锁（认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改）

4.**CAS会带来什么问题？**

（1）ABA问题. CAS需要在操作值的时候，检查值有没有发生变化，比如没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时则会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A。

JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前版本号是否等于预期版本号，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值，内部使用Pair来存储元素值及其版本号

（2）循环时间长开销大：CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销

（3）只能保证一个共享变量的原子操作：

对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

- Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。
- 把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i = 2，j = a，合并一下ij = 2a，然后用CAS来操作ij

5.**AtomicInteger类的底层实现和源码分析**：

使用Unsafe库中封装的CAS方法以及Volatile修饰int value值来实现的线程安全三特性

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2017.png)

除了原子更新基本类型，还提供了原子更新数组和原子更新引用类型，原子更新字段类

原子更新引用类型：

AtomicReference: 原子更新引用类型。 

AtomicStampedReference: 原子更新引用类型, 内部使用Pair来存储元素值及其版本号。 

AtomicMarkableReferce: 原子更新带有标记位的引用类型。

### **锁核心类AQS：**

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2018.png)

1.什么是AQS？为什么它是锁的核心部分

****AbstractQueuedSynchronizer，****是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出大量应用广泛的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。它的核心思想是如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

![Untitled](%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%203f306/Untitled%2019.png)

AQS使用一个int成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。

```java
private volatile int state;//共享变量，使用volatile修饰保证线程可见性
```

AQS定义了两种资源共享方式：

- **Exclusive**（独占）：只有一个线程能执行，如 `ReentrantLock`。又可分为公平锁和非公平锁：
    - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
    - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的
- **Share**（共享）：多个线程可同时执行，如`CountDownLatch`、`Semaphore`、 `CyclicBarrier`、`ReadWriteLock`
- 

AQS实现了以下重要逻辑：

- **状态的原子性管理**
- **线程的阻塞与解除阻塞**
- **队列的管理**

AQS的三大核心就是状态，队列和期望实现类实现的获取/释放等重要方法

**状态**：

tate 的含义并不是一成不变的，它会根据具体实现类的作用不同而表示不同的含义

在**Semaphore**里面，state 表示的是剩余许可证的数量

在 **CountDownLatch** 工具类里面，state 表示的是需要“倒数”的数量

在 **ReentrantLock** 中它表示的是锁的占有情况。最开始是 0，表示没有任何线程占有锁；如果 state 变成 1，则就代表这个锁已经被某一个线程所持有了。ReentrantLock 是可重入的，同一个线程可以再次拥有这把锁就叫重入。如果这个锁被同一个线程多次获取，那么 state 就会逐渐的往上加，state 的值表示重入的次数。

**FIFO队列**：

存储等待线程。多个线程同时争抢锁，大部分线程抢不到，AQS的FIFO队列负责充当“排队管理器” ，是一个双向链表。

**获取/释放 方法**

不同工具类实现各不相同。

获取 方法(通常都会与state相关)

- ReentrantLock中lock:state不为0且当前线程不是持有锁的线程，代表锁被其他线程持有，让该线程进入阻塞状态。
- Semaphore中的acquire方法是获取许可证，取决于state,state>0说明有剩余许可证，数量足够可以获取；state=0，说明没有许可证，进入阻塞状态。
- CountDownLatch的await方法。作用是等待，直到倒数结束，state!=0线程就阻塞，state=0门闩放开，阻塞线程会被唤醒

释放 方法

与获取方法相反，通常是让state数扣减，贴近0，

CountDownLatch：

在构造CountDownLatch的时候需要传入一个整数n，在这个整数“倒数”到0之前，主线程需要等待在门口，而这个“倒数”过程则是由各个执行线程驱动的，每个线程执行完一个任务“倒数”一次。总结来说，CountDownLatch的作用就是等待其他的线程都执行完任务，必要时可以对各个任务的执行结果进行汇总，然后主线程才继续往下执行。

CountDownLatch主要有两个方法：countDown()和await()。countDown()方法用于使计数器减一，其一般是执行任务的线程调用，await()方法则使调用该方法的线程处于等待状态，其一般是主线程调用

我们要读取处理 6 个文件，这 6 个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理。

为此我们定义了一个线程池和 count 为 6 的`CountDownLatch`对象 。使用线程池处理读取任务，每一个线程处理完之后就将 count-1，调用`CountDownLatch`对象的 `await()`方法，直到所有文件读取完之后，才会接着执行后面的逻辑。

```java
public class CountDownLatchExample1 {
    // 处理文件的数量
    private static final int threadCount = 6;

    public static void main(String[] args) throws InterruptedException {
        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {
                try {
                    //处理文件的业务操作
                    //......
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    //表示一个文件已经被完成
                    countDownLatch.countDown();
                }

            });
        }
        countDownLatch.await();
        threadPool.shutdown();
        System.out.println("finish");
    }
}
```

**JUC的并发容器**：

****ConcurrentHashMap：****和HashTable的区别在于不是使用synchronized而是用分段锁，所以性能更快

****CopyOnWriteArrayList：****读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 `List` 的内部数据，毕竟读取操作是安全的。并且写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待

读取操作没有任何同步控制和锁操作，理由就是内部数组 `array` 不会发生修改，只会被另外一个 `array`替换，因此可以保证数据安全。

使用fail-safe机制****，****在写操作时（加锁），先将当前容器复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器

发现在添加的时候是需要加锁的，否则多线程写的时候会复制出N个副本出来……

读的时候不需要加锁，如果读的时候有多个线程正在向ArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的ArrayList。

CopyOnWrite的应用场景：CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。

缺点：写时复制的机制会导致每次写都要复制内存，开销很大

数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的，所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。

**非阻塞队列ConcurrentLinkedQueue**：既然是非阻塞，那么就是和CAS算法有关。适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 `ConcurrentLinkedQueue`
 来替代

**阻塞队列BlockingQueue：**ArrayBlockingQueue，LinkedBlockingQueue，PriorityBlockingQueue。并发控制采用的是可重入锁 `ReentrantLock`

不管是插入操作还是读取操作，都需要获取到锁才能进行操作