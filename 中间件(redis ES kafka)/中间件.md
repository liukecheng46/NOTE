# 中间件

工作中如何使用redis ES和kafka的：

中间件用的什么版本？

redis用的什么版本 每个版本有什么区别 [https://www.cnblogs.com/xingxia/p/redis_versions.html](https://www.cnblogs.com/xingxia/p/redis_versions.html)（6以后的版本）

ES集群提供的是2.X版本，High rest Client 6.X  
kafka版本是2.X

线上如何查看中间件和jvm运行参数并进行调优

持久化：es通过translog刷盘来提供持久化

kafak本来就是磁盘的，partition就是物理地址，写到partition中就是写在磁盘上，partition就等于日志文件

spring 怎么加载redis 添加spring-data-redis依赖 写一个redis配置类 函数返回RedisTemplate和StringRedisTemplate，用bean注入容器

如果是用redission的话那就是配置类返回`RedissonClient`

spring 怎么记载es  添加High-rest-client依赖  写一个es配置类 函数返回`RestHighLevelClient` 用bean注入容器（单例）

spring 怎么加载kafka 添加spring-kafka依赖  配置类返回`kafkaTemplate` 用这个的send（）来发送消息，消费者的话在消费者方法上加`@KafkaListener(topics = {"hello2"})`注解就可以消费分区的消息

**Redis**：Redis入门指南 **[Redis实战](https://book.douban.com/review/9637142/)**

java客户端Redisson

优势：

1. 支持10w/s读写
2. 所有操作自带原子性，还支持对操作合并后的原子性执行
3. 丰富强大的数据类型
4. 成熟的持久化 RDB AOF
5. 支持发布订阅模式
6. 支持分布式 Redis Cluster，读写分离和主从复制
7. 使用多路 I/O 复用模型，非阻塞 IO

常见应用：高读写实现热点数据缓存（作为缓存使用的时候使用**一致性哈希**实现动态扩容缩容）；expire设置过期时间可以用在限时优惠、验证码等业务场景；原子性的操作用于计数器相关场景（高并发秒杀，分布式序列号生成...）；stenx命令实现分布式锁（也是用在秒杀系统中）；sortedSet可以实现排行榜相关场景；集合的一些命令可以实现朋友圈/Feed流系统中点赞、好友等相互关系；订阅功能可以实现订单失效时间等延时操作。

基础数据类型：[https://pdai.tech/md/db/nosql-redis/db-redis-data-types.html](https://pdai.tech/md/db/nosql-redis/db-redis-data-types.html)

String字符串 key-value：可以用作缓存，INCR和DECR操作可以用于计数器

List双向链表：可以用于朋友圈/微博的timeline功能，还有消息队列

Set集合（String类型的无序集合）：通过哈希表实现，增删查复杂度都是o(1)；可以用于标签，点赞，收藏等功能

Hash表：缓存，和String的区别：建议是大部分情况下使用 String 存储就好，毕竟在存储具有多层嵌套的对象时方便很多，占用的空间也比 Hash 小。当我们需要存储一个特别大的对象时，而且在大多数情况中**只需要访问该对象少量的字段**时，可以考虑使用 Hash

Zset有序集合：和集合实现一样也是 string 类型元素的集合,通过哈希表实现，不允许重复的成员。不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序；**数据少时用ziplist，数据量大用hash加skiplist（节省空间，优化性能，性能和空间折中）**，用于排行榜。

zset的聚合元素可以统计在线用户，或者x天内人数等等

**redis map渐进式扩容和concurrentHashmap扩容的区别**：

redis是单进程的渐进式扩容，单线程是指只有一个线程在扩容，而在扩容的同时其他的线程可以并发的进行读写，过程会设计到一系列锁来保证同步性

![Untitled](中间件/Untitled.png)

concurrentHashmp的同步策略是多线程协同式rehash：有多个线程并发的把数据从旧的容器搬运到新的容器中

![Untitled](中间件/Untitled%201.png)

特殊数据类型：

HyperLogLogs基数统计：省内存的进行大数据计数，但是有0.81%的错误率

Bitmap位图：省内存

geospatial地理位置（实现原理Zset）：计算两地之间的距离, 方圆几里的人

redis5.0新增了一个**Stream类型**，鉴了Kafka的设计，是一个新的强大的支持多播的可持久化的消息队列。旧版本redis实现消息队列的方式有订阅/发布模式和基于List，但是支持方式都有缺陷。

底层数据结构类型：

![Untitled](中间件/Untitled%202.png)

1.Sds简单字符串

2.ZipList压缩列表：为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储

3.QuickList快表：以zipist为节点的双端链表。list作为最传统的双链表, 结点通过指针持有数据, 指针字段会耗费大量内存. ziplist解决了耗费内存这个问题. 但引入了新的问题: 每次写操作整个ziplist的内存都需要重分配. quicklist在两者之间做了一个平衡.

4.Dict哈希表：**渐进式Hash-扩容**和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。**但是进行 增加操作，一定是在新的哈希表上进行的**。

5.Inset整数集：实现set

6.**ZSkipList跳表**：作为有序集合 (Zset) 的实现。跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这就是跳跃表的长处。跳跃表的缺点就是需要的存储空间比较大，属于利用空间来换取时间的数据结构

**为什么用跳表不用平衡树或者哈希表**：作者的注释是说实现简单且达到了类似效果。

![Untitled](中间件/Untitled%203.png)

跳表每插入一个新元素，一直抛硬币，是正面就累加，反面的时候停止，最后记录的次数作为该元素的最高层（具体实现可见[https://leetcode-cn.com/problems/design-skiplist/solution/javashou-xie-shi-xian-tiao-biao-by-feng-omdm0/](https://leetcode-cn.com/problems/design-skiplist/solution/javashou-xie-shi-xian-tiao-biao-by-feng-omdm0/)）

**持久化-RDB和AOF机制**：

Redis是个基于内存的数据库。那服务一旦宕机，内存中的数据将全部丢失。通常的解决方案是从后端数据库恢复这些数据，但后端数据库有性能瓶颈，如果是大数据量的恢复，1、会对数据库带来巨大的压力，2、数据库的性能不如Redis。导致程序响应慢。所以对Redis来说，实现数据的持久化，避免从后端数据库中恢复数据，是至关重要的。

RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。

父进程和子进程的内存关系也是这个（读时共享，写时复制）

**fork子进程+写时复制**：

主进程为了在这个过程中继续服务，**调用fork函数（重操作）产生一个子进程**，子进程负责持久化的过程，主进程继续负责提供服务。通过fork函数创建子进程后，**父子进程共享同一份数据，子进程初始不复制数据**，数据只在要写的时候才会进行复制-在RDB的过程中如果修改某一个数据，这块数据就会被复制一份，生成该数据的副本。然后，子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。这样保证了快照保存的只是那一刻的数据，之后的修改不会在快照中体现（Copy-on-write）fail-safe机制

![Untitled](中间件/Untitled%204.png)

RDB分手动触发和自动触发两种：手动触发指令save和bgsave，自动触发有几种情况：redis.conf中配置快照周期`save m n`，即在m秒内有n次修改时，自动触发bgsave；主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作

****RDB优缺点：****

**优点** 
• RDB文件是某个时间节点的快照，默认使用**LZF算法进行压缩，压缩后的文件体积远远小于内存大小**，适用于备份、全量复制等场景； 
• Redis**加载RDB文件恢复数据要远远快于AOF方式**；

 **缺点** 
• RDB方式实时性不够，无法做到秒级的持久化（不能保持实时一致性）； 
• 每次调用bgsave都需要fork子进程，**fork子进程属于重量级操作**，频繁执行成本较高； 
• RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全； 
• 版本兼容RDB文件问题；

AOF不是默认的持久化机制，需要设置打开，AOF日志采用**写后日志**，即先写内存，后写日志，像mysql使用的是**写前日志**

为什么redis用写后日志：要求高性能，避免额外的检查开销 Redis 在向 AOF 里面记录日志的时候，并**不会先去对这些命令进行语法检查，也不会阻塞写操作**。

风险在于如果命令执行完成，写日志之前宕机了，会丢失数据。

AOF何时将缓冲区中内容写入AOF文件中有三种策略：

![Untitled](中间件/Untitled%205.png)

**AOF的重写**：AOF会记录每个写命令到AOF文件，随着时间越来越长，AOF文件会变得越来越大。如果不加以控制，会对Redis服务器，甚至对操作系统造成影响，而且AOF文件越大，数据恢复也越慢。提供了**AOF文件重写机制**：通过创建一个新的AOF文件来替换现有的AOF，新旧两个AOF文件保存的数据相同，但**新AOF文件没有了冗余命令。主线程fork出子进程重写aof日志，子进程重写日志完成后，主线程追加aof日志缓冲，替换日志文件**。

**RDB和AOF混合使用**：内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志**也只用记录两次快照间的操作**，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销

发布/订阅模式：SUBSCRIBE 命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端

![Untitled](中间件/Untitled%206.png)

当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端

![Untitled](中间件/Untitled%207.png)

Redis事务：Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令

![Untitled](中间件/Untitled%208.png)

![Untitled](中间件/Untitled%209.png)

**Watch操作可以实现乐观锁**：如果在 WATCH 执行之后， EXEC 执行之前， 有其他客户端修改了 mykey 的值， 那么当前客户端的事务就会失败。 程序需要做的， 就是不断重试这个操作， 直到没有发生碰撞为止。这种形式的锁被称作乐观锁， 它是一种非常强大的锁机制。 并且因为大多数情况下， 不同的客户端会访问不同的键， 碰撞的情况一般都很少， 所以通常并不需要进行重试。

![Untitled](中间件/Untitled%2010.png)

Redis不支持事务回滚是因为本身就是单线程，原子性的，事务发生错误是因为错误的语法，所以不需要回滚

**如果在一个事务中的命令出现错误，那么所有的命令都不会执行**；

**如果在一个事务中出现运行错误，那么正确的命令会被执行**。

Redis为什么使用单线程：

Redis运行在内存中，读写速度很快，而**多线程上下文切换的时间消耗相较而言就比较明显**，使用单线程可以减少上下文切换的时间消耗。此外，**Redis的性能瓶颈在于内存大小以及网络带宽**，不在cpu。简单易行，指令串行，**不用维护复杂的锁机制**，避免资源竞争。同时避免了不必要的上下文切换，减少了CPU消耗。单线程天生支持原子性，在处理并发时逻辑非常简单。

单线程的缺点：某个命令执行时间过长，那么就必然造成其他命令的阻塞-持久化fork阻塞，单线程cpu饱和（很少出现，不是瓶颈）

redis6.0后引入了多线程，引入多线程主要是为了解决**网路IO**读写这个瓶颈，**执行命令还是单线程执行的**，所以也不存在线程安全问题

Redis支持ACID吗:单个操作的原子性是支持的（Redis 事务的执行并不是原子性）。一致性和隔离性也是有的，**但是redis事务不保证持久性，这是因为redis持久化策略中不管是RDB还是AOF都是异步执行的**，不保证持久性是出于对性能的考虑

redis为什么这么快：

![Untitled](中间件/Untitled%2011.png)

**Redis** 的主从复制：

**主从复制的作用**主要包括：

- **数据冗余**：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
- **故障恢复**：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
- **负载均衡**：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
- **高可用基石**：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础

![Untitled](中间件/Untitled%2012.png)

![Untitled](中间件/Untitled%2013.png)

**第一次连接到主节点-全量复制：发送RDB文件**

![Untitled](中间件/Untitled%2014.png)

**增量复制：之后都是增量复制，连接断开后也会采用增量复制的方式同步（不是发AOF，是用缓冲区发写命令）**

![Untitled](中间件/Untitled%2015.png)

如果每个slave的同步都要由master节点来处理的话，会导致master节点压力太大，可以用**主从从结构**来优化

**哨兵机制**：主节点的自动故障转移-sentinel系统可以监视一个或者多个redis master服务，以及这些master服务的所有从服务；当某个master服务下线时，自动将该master下的某个从服务升级为master服务替代已下线的master服务继续处理请求

哨兵的选举机制其实很简单，就是一个Raft选举算法： 选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举

**Redis的部署模式**：

1. 主从模式

将数据库分为主数据库和从数据库，其中主数据库一般负责写，而从数据库一般负责读，实现读写分离

原理：

- 主数据库正常配置
- 在从数据库中配置跟随的主数据库
- 主数据库收到sync指令后，通过RDB快照当前数据库，结束后发送给从服务器
- 所有的写操作都通过主数据库，然后通过异步方式向从数据库推送增量数据
- 大部分的读操作都通过从数据库
- 主数据库的写入操作和与从数据库的同步是异步进行

优点：可以合理搭配主从数据库的数量将负载有效的分担到不同配置的服务器中。缺点：由于数据库读写是在不同的数据库中异步实现，因此存在数据不同步的可能性

 2. 哨兵模式

对于一主多从的数据库模式，如果主数据库崩溃，则数据库服务中断。有了哨兵模式后，若主数据库崩溃，则可以通过哨兵监控，将从服务器转化为主服务器，哨兵之间也能相互监控。Redis-sentinel本身是一个独立运行的进程，能够监控多个master-slave集群，发现master宕机后能够进行切换

1. 集群模式

随业务量和数据量的增加，redis性能到达单节点瓶颈，垂直扩容（提升各节点自身的性能，如增加节点的储存空间）受到机器性能限制，而水平扩容（增加节点数量）涉及到对应用的影响以及数据迁移中的丢失风险。集群模式正是可以解决这些问题，用于实现负载均衡，集群模式主要可以解决分片问题，将整个数据按照规则分布在不同的子节点上，每个节点负责自己部分的数据。

Redis Cluster是一种服务端Sharding技术，Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念（hash slot算法），一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行

![Untitled](中间件/Untitled%2016.png)

Redis缓存相关问题：

缓存穿透 缓存穿击 缓存雪崩 缓存污染 缓存和数据库一致性

缓存穿透：请求缓存和数据库中都没有的数据，每一次都会去查询db。 比如攻击者发起查找id为-1的数据，每次请求都在db上。

解决办法：布隆过滤器快速判断数据库中是否有，没有则直接返回；或者接口层添加校验。

缓存击穿：访问非常频繁的热点数据过期失效-请求缓存中没有但数据库中有的高频热点数据，如果此时访问这条数据的并发特别多，一起访问db就会造成崩溃

解决方法：设置热点数据永不过期；接口限流和降级熔断-当服务down掉后，进行熔断，快速返回。

缓存雪崩：缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机；和击穿的区别在于缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

解决方法：过期时间加一个随机数，防止大量数据同一时间同时过期（削峰）；设置热点数据永不过期

缓存污染：缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间

解决方法：缓存淘汰策略-对设置了过期时间的数据或者全部数据使用random，lru，lfu算法。 redis的lru算法进行了优化：会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

**Redis的过期删除策略**：过期删除策略主要分为三种：定时删除、惰性删除以及定期删除

1. 定时删除

定时删除时设置某个key的过期时间**，一旦过期则立即执行删除操作**，优点是节约内存，缺点是消耗cpu资源

1. 惰性删除

惰性删除是指设置某个key的过期时间后，只有在下次使用它时才去检查其是否过期，若过期则删除，优点是十分节省CPU资源，缺点是是非常占用内存资源，可能会延迟删除许多key，甚至永远无法删除一些之后不会用到的key

1. 定期删除

设置key的过期时间后，每隔一段时间检查是否过期，并统一删除过期key，通过合理设置时间可以较好的综合CPU与内存资源，但是每次请求都需要判断缓存是否已经失效，逻辑相对复杂。

可见，上述过期删除策略都存在各自的优点和缺陷，单一策略的使用难以满足实际需要。因此Redis采用的是**惰性删除与定期删除**搭配使用的过期删除策略。可以理解为在惰性删除的基础上，每隔一段时间，**随机从一定数量的数据库随机抽取一定数量的key进行检查**，并清理过期键。随机抽取的策略进一步减少了对CPU资源的依赖，同时也较好的平衡了对内存资源的消耗。

**Redis缓存的内存淘汰机制**（MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据-redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略）

大体上分为全局移除和过期时间移除

![Untitled](中间件/Untitled%2017.png)

`LRU`算法需要一个双向链表来记录数据的最近被访问顺序，但是出于节省内存的考虑，`Redis`
的`LRU`算法并非完整的实现。`Redis`并不会选择最久未被访问的键进行回收**，相反它会尝试运行一个近似`LRU`的算法，通过对少量键进行取样，然后回收其中的最久未被访问的键**。通过调整每次回收时的采样数量`maxmemory-samples`

**写操作的缓存一致性问题**

- 更新缓存or直接淘汰缓存
- 先更新缓存or先更新数据库

对于第一个问题：若直接将旧数据从缓存中淘汰，操作十分简单，但下次查询到该数据时会有一次缓存未命中。而更新缓存的话，若数据较为复杂，则存在多次缓存与数据库的交互，整体消耗大，另外多个线程更新缓存也存在先后性的问题，容易造成脏读。相比较而言，**直接从缓存中淘汰旧数据，操作简单，而且最多带来一次缓存未命中的问题，更加具有优势**

对于第二个问题：

考虑先淘汰缓存，然后更新数据库：若采用同步更新缓存的策略，在高并发情况下，若某个线程先淘汰了缓存而数据库还未更新，此时另外一个线程到数据库中读取该数据并读入缓存，此时缓存中数据与数据库数据不一致，并且直到该数据下一次被更新均不一致，会带来很长时间的不一致问题。

解决办法：1. 高并发情况下，采用异步更新策略，某个线程进行写操作，先淘汰缓存，此时其它线程读取该数据只从数据库中读而不放入缓存，等到进行写操作的线程成功更新数据库后，通过订阅binlog来异步更新缓存

2. 若采取同步更新缓存策略，为解决长时间不一致问题，可以采用串行化或者是延时双删策略，写数据进程在完成数据库的更新后，休眠M秒后再次尝试淘汰缓存。延时双删一个是会降低更新操作的吞吐量，另一个是若二次缓存淘汰失败，还会造成长时间的不一致问题，因此还需要引入重试机制，即当二次淘汰失败，报错并继续重试，直至执行成功。

考虑先更新数据库，再淘汰缓存更新数据库到淘汰缓存的时间段内，数据库和缓存中的数据不一致，会造成短时间的数据不一致问题，但是此时读取效率高，此外引入重试机制可以防止淘汰缓存失败导致的数据长时间不一致问题，适用于对一致性要求不是很高的业务。

小结：

- 淘汰缓存而不是更新缓存
- **若先淘汰缓存再更新数据库**，同步更新缓存策略下存在数据长时间不一致的问题，可以采用串行化或者延时双删等策略，读取效率相对高，数据一致性需要另外保证。异步更新缓存策略下，数据始终一致，但是更新时其它线程都需要到数据库中读取数据，效率低（数据一致性高，适用于对一致性要求高的业务）
- **先更新数据库再淘汰缓存**，效率高，数据一段时间不一致，（适用于对一致性要求不太高的业务）

不论是先写db再写缓存还是先写缓存再写db都会出现一致性问题：

1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

解决方法：

最常用的**Cache Aside**模式：

- **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- **命中**：应用程序从cache中取数据，取到后返回。
- **更新**：**先把数据存到数据库中，成功后，再让缓存失效**（**为什么不更新缓存：防止两个并发的写导致脏数据**）

脏读情况：一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。

这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存。所以Facebook使用了这个降低概率的方法，因为严格保持一致性的方法中2PC太慢，而Paxos太复杂

还有一种方法，在数据库写完后，**将需要删除的key发送到消息队列**，redis消费消息来进行删除操作。对业务线代码造成大量的侵入。所以还有一种优化：不用消息队列，redis订阅数据库的binlog，通过binlog进行删除操作，类似于数据库的主从复制

引申：**CPU的缓存一致性是如何保证的**

cpu本身有一个多级（L1,L2,L3）的高速缓存，是位于cpu和内存之间的缓冲区

- 时间局部性：如果某个数据被访问，那么不久的将来他很可能被再次访问。
- 空间局部性：如果某个数据被访问，那么与他相邻的数据很快也可能被访问。

那就会有多核cpu多级缓存和内存不一致的问题，如何保证呢？

写的话有两种方案

- 写失效：当一个 CPU 修改了数据，如果其他CPU有该数据，则通知其为无效。
- 写更新：当一个 CPU 修改了数据，如果其他CPU有该数据，则通知其更新数据。

引入缓存一致性协议****MESI 协议****：

- 写传播（Write propagation）：一个处理器对于某个内存位置所做的写操作，对于其他处理器是可见的
- 写串行化（Write Serialization）：对同一内存单元的所有写操作都能串行化。即所有的处理器能以相同的次序看到这些写操作

****MESI 协议是强一致性的，但是性能很差，所以最终cpu选择了相对弱一点的最终一致性—在某些中间状态下，多个 CPU 之间的数据并不一致。同时也可能会发生乱序执行的情况，也就是重排序。进行cpu的指令重排序，具体靠lock的内存屏障实现。****

JMM定义了语言层面上的抽象内存一致性模型 as-if-serial和happens-before

redis和memcached的区别：

1.memcached只支持key-value，redis有更多的数据结构，除了缓存外的更多功能

2.redis只用单核单线程，memcached可以多核多线程

4.memchaed没有持久化

5.redis不是纯内存，当物理内存用完时，可以将一些很久没用到的value 交换到磁盘

redis面试问题总结（进阶版）：[https://pdai.tech/md/db/nosql-redis/db-redis-z-mianshi.html](https://pdai.tech/md/db/nosql-redis/db-redis-z-mianshi.html)

redis实现分布式session ：`spring-session-data-redis` `@EnableRedisHttpSession`

**setnx实现分布式锁**： setnx 的意思是set if not exists

setnx key value 在指定的key不存在时，为key设置指定的值，如果返回1，说明key不存在，设置成功，返回0说明key已经存在

在分布式应用中，如果需要拿锁，就调用setnx方法：

SETNX lock.foo <current Unix time + lock timeout + 1>（过期时间一般为几秒）

返回1说明获得锁成功，将键 lock.foo 的值设置为锁的超时时间（当前时间 + 锁的有效时间）。返回0说明其他进程获得了锁，操作执行完后调用del操作删除这个key

如果拿锁的进程异常退出，没有释放这个锁，那其他进程也可以通过超时时间判断是否超时，那么如何处理多个进程拿锁冲突的情况呢？

![Untitled](中间件/Untitled%2018.png)

如何防止过期时间到了，但是拿锁应用还没有执行完：**可**以在加锁时，先设置一个预估的过期时间，然后开启一个守护线程，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行续期，重新设置过期时间（redisson自带这个功能）

分布式锁可以解决秒杀项目中的超卖问题，可以直接用官方的RedLock分布式锁实现

Redlock主要进一步解决了集群宕机的问题：客户端A获得主服务器上的锁，然后主服务器向从服务器复制数据的过程中崩了，导致数据没有复制到从数据库中，这时会在从服务器中选出来一个升级为主服务器，但新的主服务器中并没有客户端A设置的锁。所以客户端B也可以获取到锁，违背了上面说的

或者也可以用redisson自带的分布式锁，不管是`加锁`、`解锁`、`续约`都是客户端把一些复杂的业务逻辑，通过封装在`Lua`脚本中发送给`redis`，保证这段复杂业务逻辑执行的`原子性`。

redis并发竞争问题解决：

事务+watch的乐观锁模式

基于setnx的分布式锁

消息队列，串行化处理

**ElasticSearch:**

数据检索，聚合查询，搜索引擎，准实时查询。

基于Lucene（高性能、全功能的搜索引擎库）的倒排索引，但是隐藏 Lucene 的复杂性，取而代之提供一套简单一致的 RESTful API。

所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度

1）海量数据的分布式存储以及集群管理，达到了服务与数据的高可用以及水平扩展；

2）近实时搜索，性能卓越。对结构化、全文、地理位置等类型数据的处理；

3）海量数据的近实时分析（聚合功能）应用场景：

1）网站搜索、垂直搜索、代码搜索；

2）日志管理与分析、安全指标监控、应用性能监控、Web抓取舆情分析；

**索引不支持更新，而是采用重新建立索引的方式**（插入只能重建索引）

不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。

**为什么叫准实时**？对 Elasticsearch 的写入操作成功后，写入的数据需要1秒钟后才能被搜索到，因此 Elasticsearch 搜索是准实时或者又称为近实时.

当写请求发送到 es 后，es 将数据暂时写入 `memory buffer` 中，此时写入的数据还不能被查询到。默认设置下，es 每1秒钟将 `memory buffer` 中的数据 `refresh` 到 Linux 的 `File system cache`，并清空 `memory buffer`，此时写入的数据就可以被查询到了。

但 `File system cache` 依然是内存数据，一旦断电，则 `File system cache` 中的数据全部丢失。默认设置下，es 每30分钟调用 `fsync` 将 `File system cache` 中的数据 `flush` 到硬盘。因此需要通**过 `translog` 来保证即使因为断电 `File system cache` 数据丢失**，es 重启后也能通过日志回放找回丢失的数据。

![Untitled](中间件/Untitled%2019.png)

es和数据库的对比：6.0.0版本开始一个索引只存储一类数据，所以type被废弃

![Untitled](中间件/Untitled%2020.png)

一般使用java High Level REST Client，把底层DSL语句基于设计模式进行了封装，像mybatis-plus一样调用：wrapperQuery-建造者模式

**ES原理**：[https://blog.csdn.net/qq_36289377/article/details/82993160](https://blog.csdn.net/qq_36289377/article/details/82993160)

value-key形式的倒排索引

![Untitled](中间件/Untitled%2021.png)

可以看到，倒排索引是针对每个字段的，每个字段都有自己的倒排索引，25、32这些叫做term，[1,3]这种叫做posting list（倒排链表）。

ES使用FST快速查找&压缩技术将Term index（前缀树 AKA 字典树）存到内存中，在内存中直接索引term所在的磁盘block，再去磁盘读取term，找到对应的posting list

FST：

1、空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；

2、查询速度快。O(len(str))的查询时间复杂度。

![Untitled](中间件/Untitled%2022.png)

当一个term对应的posting list特别大的时候，存储空间要求特别大，内存装不下怎么办：

初步解决方案-bitmap

![Untitled](中间件/Untitled%2023.png)

但是bitmap压缩也不够用，咋办呢

引入优化版bitmap - 增量bitmap

首先排序，然后将最小数后面的大数都优化为增量的小数（227=300-73),然后转换成二进制，取占最大位的数，227占8位，前三个占八位，30占五位，后三个数每个占五位

![Untitled](中间件/Untitled%2024.png)

但是增量bitmap也只是进行了线性压缩，极端情况下还是不够用

引入终极版本-Roaring Bitmap

除数分块，避免[1,99999989,....,99999999]这种特殊情况

以65535模分块（2^16-1，两个字节能表示的最大数）

如果某一个块里面的值个数小于4096，就用short的array来存，如果大于就用bitmap存（为什么是4096：固定每块内存65535 bit，这种情况下，short最多存4096个数，因此整数基数较小时，使用数组更省空间，基数较大时，使用bitmap更省空间）

![Untitled](中间件/Untitled%2025.png)

使用roaring bitmap实现了将大posting list装进内存中

es聚合（联合索引）查询：[https://www.cnblogs.com/bonelee/p/6394451.html](https://www.cnblogs.com/bonelee/p/6394451.html)

如果查询的filter缓存到了内存中（以bitset的形式），那么合并就是两个bitmap的AND。如果查询的filter没有缓存，那么就用skip list的方式去用**类多路归并**的方式找两个在磁盘上的posting list的交集，

 `*suffix -> xiffus*` 如果我们想以后缀作为搜索条件，可以为Term做反向处理

![Untitled](中间件/Untitled%2026.png)

es的关联度score是基于tfidf

**消息队列Kafka**:

消息队列的优点：

1.通过异步处理提高系统的性能（减少响应所需时间）

2.削峰平谷

3.降低系统耦合性

**异步处理**：将用户的请求数据存储到消息队列之后就立即返回结果。随后，系统再对消息进行消费。因为用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此，**使用消息队列进行异步处理之后，需要适当修改业务流程进行配合**，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。这就**类似我们平时手机订火车票和电影票**

削峰平谷：**将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。**举例：在电子商务一些秒杀、促销活动中，合理使用消息队列可以有效抵御促销活动刚开始大量订单涌入对系统的冲击

降低系统耦合性：各个子系统之间如果不使用接口或者RPC调用，而是通过信息队列传输数据的话，新增模块或者修改模块就对其他模块影响较小

![Untitled](中间件/Untitled%2027.png)

解耦基于事件驱动的发布/订阅模式：消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。消息接受者对消息进行过滤、处理、包装后，构造成一个新的消息类型，将消息继续发送出去，等待其他消息接受者订阅该消息

除了发布/订阅模式，还有点对点模式和队列等其他模式

引入消息队列带来的问题：

MQ挂掉带来的可用性问题。

消息重复消费、消息丢失的情况、消息传递的顺序性。

延迟带来的一致性问题

Kafka提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。kafka 唯一的一点劣势是有可能消息重复消费

![Untitled](中间件/Untitled%2028.png)

kafka的构造：

****Producer、Consumer、Broker、Topic、Partition****

![Untitled](中间件/Untitled%2029.png)

1. **Producer（生产者）** : 产生消息的一方。
2. **Consumer（消费者）** : 消费消息的一方。
3. **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。
- **Topic（主题）** : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。
- **Partition（分区）** : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。

**多分区机制**：通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）

消费者组：*消费*组是一个逻辑上的概念，它将旗下的*消费者*归为一类

- 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。
- 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。

可以通过消费者组让一条消费被多个在不同消费者组下的消费者消费（**这种情况下就不能保证顺序了**）

![Untitled](中间件/Untitled%2030.png)

**Partition的多副本机制：**

Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

生产者和消费者只与 leader 副本交互。可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性，提高容灾能力。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选

Zookeeper：负责Kafka的元数据管理，比如Broker、Topic注册，通过心跳机制检查每个节点的连接，在集群中不同节点之间进行通信

**Kafka是如何保证消息的消费顺序**？

Partition分区中新消息会加在最后面，使用偏移量offsetr来保证消息在单个Partition分区内的顺序性

![Untitled](中间件/Untitled%2031.png)

而对于每个topic的多Partition，如何保证消息顺序呢：

1.每个topic只创建一个partition，但是这样就破坏了 Kafka 的设计初衷，并发能力弱

2.生产者在发送消息的时候指定要发送到哪个Partition(分区)，消费者也消费指定分区的消息（**一个分区只能被一个消费者消费**）

****Kafka 如何保证消息不丢失？****

生产者丢失消息：为send函数添加回调函数，发送失败的话返回原因并重新发送

回调函数使用guava的ListenableFuture去监听get函数，异步使用

```java
 ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
 future.addCallback(result -> logger.info("生产者成功发送消息到topic:{} partition:{}的消息", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
                ex -> logger.error("生产者发送消失败，原因：{}", ex.getMessage()));
```

消费者丢失消息：

消费者在拉取到分区的某个消息之后，消费者会自动提交offset，如果消费者还没真正消费却挂掉后丢失消息，此时offset已经提交但是却没有消费消息

解决办法：**关闭自动提交offset，每次在真正消费完消息后手动提交offset**（可能会带来重复消费的问题，消费了但还没提交offset就挂掉。一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底）

Kafka丢失消息：Partition多副本机制中，**当leader挂掉，而follower中选出的leader还没有同步完所有数据，就会有消息丢失**，有多种解决方法：

设置**acks=all**，当我们配置 **acks = all** 代表所有副本都要接收到该消息之后该消息才算真正成功被发送。

****Kafka 如何保证消息不重复消费？****

没办法做到，**只能想办法做到消费是幂等性的，即重复消费多次，你得确保对应的数据是不会改变的，不能出错**。这个要按照业务具体分析。

kafka的高可用机制是什么？

**多副本冗余**的高可用机制,producer、broker 和 consumer 都会拥有多个.

分区选举机制 、 消息确认机制

kafka为什么吞吐量这么高？

Reator 网络模型。**sendfile的零拷贝 数据压缩**....

![Untitled](中间件/Untitled%2032.png)

分布式的CAP为什么无法被同时满足（P一般是一定要实现的，C和A选一）：

某刻N1和N2节点的连接断开，如果满足分区容错性，那是可以正常请求的。有用户向N1发送了请求更改了数据，将数据库从V0更新成了V1。由于网络断开，所以N2数据库依然是V0，如果这个时候有一个请求发给了N2，但是N2并没有办法可以直接给出最新的结果V1，这个时候该怎么办呢？

这个时候无法两种方法，**一种是将错就错，将错误的V0数据返回给用户。第二种是阻塞等待，等待网络通信恢复，N2中的数据更新之后再返回给用户**。显然前者牺牲了一致性，后者牺牲了可用性。