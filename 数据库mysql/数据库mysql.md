# 数据库mysql

`高性能MySQL`

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled.png)

超键、候选键、主键：

**超键(**super key):在关系中能唯一标识[元组](https://so.csdn.net/so/search?q=%E5%85%83%E7%BB%84&spm=1001.2101.3001.7020)的属性集称为关系模式的超键

**候选键**(candidate key):不含有多余属性的超键称为候选键

**主键(**primary key):用户选作元组标识的一个候选键程序[主键](https://so.csdn.net/so/search?q=%E4%B8%BB%E9%94%AE&spm=1001.2101.3001.7020)

（java开发手册：1.不得使用外键与级联更新，一切外键概念必须在应用层解决

2.存储过程有点像数据库里的函数，预编译一次后可以直接执行，但是开发手册禁止使用存储过程，难以调试和扩展，且没有移植性）

Mysql数据存储类型：

整形：TINYINT,SMALLINT,MEDIUMINT,INT,BIGINT

浮点数：FLOAT,DOUBLE,DECIMAL

字符串：CHAR、VARCHAR，VARCHAR是变长的，能够节省空间，只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。VARCHAR 会保留字符串末尾的空格，而 CHAR 会删除。

些情况使用VARCHAR是合适的：字符串的最大长度比平均长度大很多；列的更新很少，所以碎片不是问题；使用了像UTF-8这样复杂的字符集，每个字符都使用不同的字节数进行存储。CHAR适合存储很短的字符串，或者所有值都接近同一个长度，如密码的MD5值。对于经常变更的数据，CHAR也比VARCHAR更好，因为CHAR不容易产生碎片

VARCHAR(5)和VARCHAR(200)存储"hello"的空间开销是一样的。那么使用更短的列有什么优势吗？更长的列会消耗更多的内存，因为MySQL通常会分配固定大小的内存块来保存内部值。尤其是使用内存临时表进行排序或其他操作时会特别糟糕。在利用磁盘临时表进行排序时也同样糟糕。

日期类型：DATETIME 和 TIMESTAMP，DATETIME和时区无关，TIMESTAMP和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。

大类型数据：BLOB和TEXT都是为存储很大的数据而设计的数据类型，分别采用二进制和字符方式存储。MySQL对BLOB和TEXT列进行排序与其他类型是不同的：它只对每个列的最前max_sort_length个字节而不是整个字符串做排序。同样的，MySQL也不能将BLOB或TEXT列全部长度的字符串进行索引

尽量选择更小的数据类型，尽量避免NULL：可为NULL 的列使得索引、索引统计和值比较都更复杂。尽管把可为NULL的列改为NOT NULL带来的性能提升比较小，但如果计划在列上创建索引，就应该尽量避免设计成可为NULL的列

内连接，自然连接，外连接：[https://www.cnblogs.com/isalo/p/15384186.html](https://www.cnblogs.com/isalo/p/15384186.html)

join就是inner join，而且等价于where a.x=b.y，不会消除重复列。自然连接会消除重复列，不需要指定where

Select …… from 表1 （inner） join 表 2 on 表1.A=表2.E

等价于Select a.*,b.* from a,b where a.x = b.y

事务的ACID：

 **1. 原子性(Atomicity)**

事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。

回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

**2. 一致性(Consistency)**

数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。

3. **隔离性(Isolation)**

一个事务所做的修改在最终提交以前，对其它事务是不可见的。

4**. 持久性(Durability)**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。

MySQL 默认采用自动提交模式。也就是说，如果不显式使用`START TRANSACTION`
语句来开始一个事务，那么每个查询都会被当做一个事务自动提交

**数据库的并发一致性问题（丢失了隔离性）**：

丢失修改：1先改，2再改，2的修改覆盖了1的修改

脏读： 1修改了数据，2读取这个数据，之后1撤销了修改，2读的就是脏数据

不可重复读：2读取数据，1之后对数据进行了修改，2再次读取发现和第一次结果不同，丢失了幂等性。

幻读：2读取某个范围的数据，1在这个范围内插入或删除了数据，2再次读取的时候发现和第一次结果不同，丢失了幂等性。

**隔离级别**：

未提交读：最低级别，1可以读取到2修改过但没提交的数据

提交读：1只能在2修改并提交后才能读取到2修改后的数据，解决了脏读问题。

可重复读（默认级别）：1只能在2修改并提交后，且自己也提交后，才能读取到2修改后的数据，解决了不可重复读的问题

可串行化：除了读读操作以外都会互相阻塞（串行化执行），进一步解决了幻读的问题。

MySQL支持数个存储引擎作为对不同表的类型的处理器

mysql的两种主要引擎：

I**nnoDB存储引擎（默认引擎）**：InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别。 InnoDB表是基于聚族索引建立的，因此必须要有主键，聚族索引通过主键查询有很高的性能，支持事务、异常崩溃后的安全恢复、行级锁和外键。适合频繁修改以及涉及到安全性较高的应用

**MyISAM存储引擎：**基于非聚族索引，不支持事务，不支持行级锁，最小粒度是表锁，因此并发访问受限，且崩溃后无法安全恢复，提供高速存储和检索，以及全文搜索能力，适合查询以及插入为主的应用

**事务**：如果需要事务，选择InnoDB，不需要事务，并且主要是INSERT 和 SELECT操作，那么MyISAM是不错的选择。 

**备份**：如果可以定期的关闭服务器进行备份，那么备份的因素可以忽略。反之，如果需要热备份，那么选择InnoDB引擎。

 **崩溃恢复**：MyISAM崩溃恢复后发生损坏的概率比InnoDB高的多，而且恢复速度也很慢，所以即时不需要支持事务，很多人也选择InnoDB，这是一个很重要的因素。 

**日志型应用**：对插入速度有很高的要求，可以考虑使用MyISAM，开销低，插入快。只读或者大部分情况下只读的表：读多写少的业务，如果不介意MyISAM的崩溃恢复，选用MyISAM是合适的。不要低估崩溃后恢复问题的重要性（MySIAM引擎是只将数据写到内存中，然后操作系统定期将数据刷到磁盘中）。 **订单处理**
：涉及到订单处理，那么支持事务就是必须选项。InnoDB是支持订单处理的最佳选择。 

**电子公告牌和主题讨论论坛**：如select count(*) from table;对MyISAM是比较快的，但对于其他的存储引擎可能都不行。 

**大数据量**：几个TB的数据量，需要合理的选择硬件，做好物理涉及，并对服务器的I/O瓶颈做好规划。在这样的数据量下，如果选用MyISAM，如果崩溃了，那么进行数据恢复基本就是凉凉

更改表的存储引擎（可以用mysqldump工具将数据导入导出）：

CREATE TABLE innodb_table like myTable; 

ALTER TABLE innodb_table ENGINE = INNODB; 

INSERT INTO innodb_table SELECT * FROM myTable;

[https://javaguide.cn/database/mysql/innodb-implementation-of-mvcc](https://javaguide.cn/database/mysql/innodb-implementation-of-mvcc/#%E9%94%81%E5%AE%9A%E8%AF%BB)/

[https://pdai.tech/md/db/sql-mysql/sql-mysql-mvcc.html](https://pdai.tech/md/db/sql-mysql/sql-mysql-mvcc.html)

多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，是用来解决**读-写冲突的无锁并发控制**，通过保存数据在某个时间点的快照来实现并发控制。用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。

MVCC（有点像行级锁的升级）的思想就是保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制。这样我们就可以通过比较版本号决定数据是否显示出来，读取数据的时候不需要加锁也可以保证事务的隔离效果。

通过自增的事务ID以及行记录的隐藏列记录最后操作这个数据的事务ID和回滚指针(指向undo log，通过这个重建历史版本数据)，比如说select时只查找版本早于当前事务版本的数据

Read View在事务执行快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID，根据Read View和当前事务id来确定数据的可见性，不可见的话那就通过回滚指针去undo log中重建历史版本数据（Read Repetited模式下 只会用第一版Read View，而不是每次都生成新的）

Read view 过程：

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%201.png)

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%202.png)

InnoDB在可重复读模式下不能避免幻读，但是加上Next-Key Locks锁机制后可以避免幻读（锁定一个范围，并且锁定记录本身-当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据）

在事务中混合使用存储引擎是不可靠的

因为事务是由下层的存储引擎实现，所以如果在同一个事务中混合使用了事务型和非事务型的表（innodb和myisam），当需要回滚的时候，非事务型引擎的表上的操作无法变更，就会出现不一致的情况

使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认Row-Level Lock，所以只有「明确」地指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住)。

select `for update`是一种手动`行级锁`，又叫`排它锁`，也是一种悲观锁。其它用户只能查询但不能更新被加锁的数据行。通常情况下，select语句是不会对数据加锁，妨碍影响其他的DML和DDL操作。同时，在MVCC的支持下，select语句也不会被其他类型语句所阻碍

2PL两段锁协议：事物分两个阶段，一个阶段获取锁，一个阶段释放锁-如果一个transaction释放了它所持有的**任意一个锁**，那它就**再也不能获取任何锁**。

## **索引**

前置知识—— 平衡树、b-tree、b+tree ：

每个结点最多m个子结点。除了根结点和叶子结点外，每个结点最少有m/2（向上取整）个子结点。如果根结点不是叶子结点，那根结点至少包含两个子结点

[https://blog.csdn.net/m0_50180963/article/details/108629876](https://blog.csdn.net/m0_50180963/article/details/108629876)

[https://www.cnblogs.com/nullzx/p/8729425.html](https://www.cnblogs.com/nullzx/p/8729425.html)

b+树和红黑树的比较：

1.红黑树是二叉树，所以深度比b+树大，平均磁盘查找次数更多

2.b+树符合磁盘结构，叶子节点的双向链接可以顺序读相邻节点

b树减少了查询次数（IO次数），B+树在B树上进一步进行了优化：

1. 只有叶子节点存数据信息。B-Tree的每个结点（这里的结点可以理解为一个数据页）都存储主键+实际数据，而B+Tree非叶子结点只存储关键字信息，而每个页的大小有限是有限的，所以同一页能存储的B-Tree的数据会比B+Tree存储的更少。这样同样总量的数据，B-Tree的深度会更大，增大查询时的磁盘I/O次数，进而影响查询效率
2. 叶子节点形成一层双向链表，所以在找大于某个关键字或者小于某个关键字的数据的时候，B+Tree只需要找到该关键字然后沿着链表顺序遍历就可以了，而B-Tree还需要遍历该关键字结点的根结点去搜索

也可以用create index indexName on table_name(column_name)

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%203.png)

INNODB聚簇索引 MYISAM非聚簇索引对比：

对于**非聚簇索引**来说，表数据和索引是分成两部分存储的，**主键索引和二级索引存储上没有任何区别**。使用的是B+树作为索引的存储结构，所有的节点都是索引，叶子节点存储的是索引+索引对应的记录的地址。

对于**聚簇索引**来说，表数据是和主键一起存储的，主键索引的叶结点存储**行数据**(包含了主键值)，二级索引的叶结点存储行的主键值（需要回表）。使用的是B+树作为索引的存储结构，非叶子节点都是索引关键字，但非叶子节点中的关键字中不存储对应记录的具体内容或内容地址。叶子节点上的数据是主键与具体记录(数据内容)。

![%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%204.png](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%204.png)

聚簇索引优劣：

优点：

1.当你需要取出一定范围内的数据时，用聚簇索引比用非聚簇索引好，由于行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问，不必访问磁盘。这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了。
2 主键访问更快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次I/O。
3.使用**覆盖索引**（创建一个索引，该索引包含查询中用到的所有字段，就称为覆盖索引）扫描的查询可以直接使用叶节点中的索引值，不再需要回表查询。

缺点：

1.插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键，并且当性能差时就要进行索引重建。

2.二级索引访问需要两次索引查找，非聚簇索引的二级索引只需要一次。

3.更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新

4.二级索引相对较大，因为二级索引的叶子节点保存了所有主键信息

INNODB会默认创建主键索引，没有指定主键的话会自动选择一个可以唯一标识数据记录的列，如果不存在的话就会自动生成一个隐藏的自增主键，二级索引一般是后续为了构造某些查询的覆盖索引自行添加。

为什么聚簇索引主键要自增：聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。如果主键不是自增id，那么可以想 象，它会不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。

B+ Tree索引优点
  ①.全值匹配：指的是和索引中所有列进行匹配。假设以(姓，名，出生日期)三个数据项建立复合索引，那么可以查找姓名为张三，出生日期在2000-12-12的人
  ②.匹配最左前缀：假设以(姓，名，出生日期)三个数据项建立复合索引，可以查找所有姓张的人
  ③.匹配列前缀：假设有姓为司徒，司马的人，我们也可以查找第一列的前缀部分，如查找所有以司开头的姓的人
  ④.匹配范围值：可以查找所有在李和张之间的姓的人，注意范围查询只在复合索引的优先排序的第一列。（假设姓名按照拼音排序）
  ⑤.精确匹配前面列并范围匹配后一列：可以查找姓李并出生日期在2000-12-12之后的人或姓名为张三并出生日期在2000-12-12之后的人，注意范围第一个范围查询后面的列无法再使用索引查询
  ⑥.只访问索引的查询：即查询只需访问索引，而无需访问数据行。（此时应想到索引中的覆盖索引）

B+ Tree索引缺点
  ①.如果不是按照索引的最左列开始查找，则无法使用索引。如无法查找名为龙的人，也无法查找在2000-12-12之后出生的人，当然也无法查找姓中以龙结尾的人（注意为和含有的区别）
  ②.不能跳过索引中的列：无法查找姓李并在2000-12-12之后出生的人
  ③.如果查询中包括某个列的范围查询，则其右边所有列都无法使用索引优化查询

哈希索引优点
  ①.快速查询：参与索引的字段只要进行Hash运算之后就可以快速定位到该记录，时间复杂度约为1

哈希索引缺点
  ①.哈希索引只包含哈希值和行指针，所以不能用索引中的值来避免读取行
  ②.哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序和范围查询
  ③.哈希索引也不支持部分索引列查询，因为哈希索引始终是使用索引列的全部数据进行哈希计算的。
  ④.哈希索引只支持等值比较查询，如=，IN()，<=>操作
  ⑤.如果哈希冲突较多，一些索引的维护操作的代价也会更高

b+树索引  b树索引  哈希索引对比：

![%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%205.png](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%205.png)

![%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%206.png](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%206.png)

![%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%207.png](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%207.png)

还有全文索引（倒排索引）和空间索引（Geo）

**MySQL执行一个查询的过程**

1. 客户端发送一条查询给服务器。
2. 服务器会先查询缓存，如果命中了缓冲，则立刻返回存储在缓存中的结果。否则，进入下一阶段。（MySQL 8.0 版本后移除缓存）
3. 服务器进行SQL解析，预处理，再由优化器生成对应的执行计划。
4. MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询。
5. 将结果返回给客户端，

**执行计划:**MySQL生成查询（多表查询）的一颗指令树，然后通过执行引擎完成这颗指令树并返回结果。最终的执行计划包含了重构查询的全部信息。MySQL的执行计划是一颗左侧深度优先的树,通过在执行语句前加explain可以查看执行计划

Explain的重要参数：

- select_type : 查询类型，有简单查询、联合查询、子查询等

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%208.png)

- type：如何进行扫描 all表示全表 index表示全索引 rang表示索引范围扫毛

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%209.png)

- key : 使用的索引
- rows : 扫描的行数

MySQL总是通过创建并填充临时表的方式来执行UNION查询。因此很多优化策略在UNION中会失效。 经常需要手工的将WHERE，LIMIT,ORDER BY等子句“下推”到UNION的各个子查询中，以便优化器能够充分利用这些条件进行优化

mysql icp优化：[https://juejin.cn/post/6865177273528811533](https://juejin.cn/post/6865177273528811533)

尽量少进行索引重建，多使用索引合并（碎片过多）：

合并索引就是将索引段中相邻的索引块其中空闲空间进行整合重组，从而释放索引块空间，这比较类似于我们windows的磁盘碎片整理，但是注意该过程不会将腾出的空间返回与数据库，而是加入到空闲空间列表中，以便下次在进行使用。这种操作对于那种以序列或是时间日志为字段的表是有非常重要价值的，因为当我们对这些表删除了大部分数据，那么其中很多空间是无法在进行使用的，那么在我们制定谓词查询的时候通常会扫描索引中很多空快，那么合并索引就将空的索引块进行释放与索引块的空闲列表中。语句非常简单：alter index index_name coalesce;合并索引与重建索引不同事，合并索引不会降低索引的高度，而是对其数据条目进行重组整合，但是重建可能会降低索引高度，另外重建索引需要2倍的磁盘空间，首先需要存储原先的索引条目数据，还需要额外的空间存储新调整 的索引数据直到重建完成才可。注：合并索引是一种在线操作，且和sql优化中的索引合并不同

覆盖索引（针对二级索引）和聚簇索引（主键索引）是有区别的：

覆盖索引(for query)是为了避免二级索引的回表，对经常查询的数据建立联合索引，即可不回表（主键索引）就查询到数据，覆盖索引不一定包括所有数据，聚簇索引（主键索引）包括所有数据

drop 删除整表

truncate 删除表中数据

delete 删除某列数据

各个范式详解：[https://pdai.tech/md/db/sql/sql-db-theory-concept.html](https://pdai.tech/md/db/sql/sql-db-theory-concept.html)

Mysql优化：

尽量控制单表数据量的大小,建议控制在 500 万以内。过大会造成修改表结构，备份，恢复都会有很大的问题。可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小

限制每张表上的索引数量,建议单张表索引不超过 5 个。索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。 因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能

禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询：无法使用覆盖索引，且可减少表结构变更带来的影响

避免使用子查询，可以把子查询优化为 join 操作：通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。因为子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询

索引字段应该是频繁查询，很少被更新的字段，且字段不为NULL，因为数据库较难优化。

字符串类型（BLOB、TEXT 和 VARCHAR）的字段上使用前缀索引（前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符）代替普通索引

对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引

切分大查询：大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

把大的连接查询分开单独查询，在应用层面进行连接

构建联合索引的时候如何选择顺序：让选择性最强的索引列放在前面。索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。

**索引失效的情况总结**：

1.**对索引使用后缀或者左右模糊匹配**：`like %xx` 或者 `like %xx%。`如果是like xx%还是会走索引的

2.**对索引字段使用函数**，会导致索引失效：select * from t_user where length(name)=6; 使用了length()函数，索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。不过mysql8.0新增了函数索引，可以对函数计算后的值建立索引:

alter table t_user add key idx_name_length ((length(name)));

3.**对索引进行表达式计算**：

select * from t_user where id + 1 = 10;是走不了索引的

但是如果改成select * from t_user where id= 10-1；就可以走索引了

4.**对索引进行隐式类型转换**：

比如本来索引是varchar类型，但是输入整形：

select * from t_user where phone = 1300000001

需要注意的是，mysql在遇到字符串和数字比较的时候，会自动把字符串转为数字再进行比较，所以对于索引是整形，但是输入字符串的例子，索引是生效的：

select * from t_user where intPhone = ”1300000001”

5.**联合索引不是最左匹配的情况**：联合索引是(a,b,c)的时候，a, ab abc可以走索引，但是b, c, bc 这种不行。需要注意的是，b<x and a=y这种 a和b都会走索引的，mysql会自动优化顺序，先找a再找b

6.****WHERE 子句中的 OR：****WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效，第二个不是索引那第一个走索引也没意义

1. != 和<>还有is null/not null会导致索引失效（not in 和!=还有<>好像在8.0之后都走索引了）

8.联合索引中范围条件（bettween、<、>、in等）右边的列都会失效

**count（*）count(1) count(主键字段) count(字段) count() 详解**：

[https://www.cnblogs.com/xiaolincoding/p/15769721.html](https://www.cnblogs.com/xiaolincoding/p/15769721.html)

![Untitled](%E6%95%B0%E6%8D%AE%E5%BA%93mysql%20f33be/Untitled%2010.png)

select count(name) from t_order;表示t_order 表中，name 字段不为 NULL 的记录数量

count(1)表示表中有多少个记录

count(主键字段)虽然是统计表中有多少个记录，但本质也是统计表的主键字段部位NULL的数量，所有相比count(1)每次还需要多比较一下主键是否为null

count(*)相当于count(0)，和count(1)没有区别

而在MyIsam引擎里，每张表都会存储row_count值，表锁保证一致性，所以执行count函数都只有O(1)复杂度

**基于undo redo，bin log日志的数据库恢复：**

redo log是InnoDb存储引擎独有的物理日志，它让Mysql拥有了崩溃恢复能力-**数据持久性**，记录在某个数据页上做了什么修改，有redo log buffer 和 redo log，什么时候从缓存写到磁盘是不一定的（事务提交前中后都可能）

bin log 是mysql级别的逻辑日志，会记录所有涉及更新数据的逻辑操作，并且是顺序写。记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层，不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog`日志。`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证**数据一致性**。事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中，保证了集群架构的数据一致性（热备份）

执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样

undo log：想要保证事务的原子性，就需要通过undo log在异常发生时，对已经执行的操作进行回滚。所有事务进行的修改都会先记录到这个回滚日志中（也是逻辑日志），然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 **回滚日志**
 中的信息将数据回滚到修改之前的样子，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。

MVCC如果判断某行数据的现在版本不可见，那么会通过隐藏列的指针找到undo log中对应的历史版本，

还可以和日志恢复算法的redo phase 和undo phase提一下：先redo所有checkpoint点之后的， 再undo那些没有commit和abort的事务

Externel merge sort:

**读写分离&主从复制**：

读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上**。**
这样的话，就能够小幅提升写性能，大幅提升读性能。

主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的主从同步延迟（强制将读请求路由到主库处理**：**同一线程主库若有写入操作，以后的读操作均从主库读取）sharding-jdbc可以实现读写分离

主从复制：MySQL binlog(binary log 即二进制日志文件) 主要记录了 MySQL 数据库中数据的所有变化(数据库执行的所有 DDL 和 DML 语句)。因此，我们根据主库的 MySQL binlog 日志就能够将主库的数据同步到从库中。mysql可以配置主从复制

主从复制架构随着用户量的增加、访问量的增加、数据量的增加依然会带来大量的问题，那就要考虑换一种解决思路。分库分表。

**分库分表**：

**分库**就是将数据库中的数据分散到不同的数据库上

**分表**就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分

- 单表的数据达到千万级别以上，数据库读写速度比较缓慢（分表）。
- 数据库中的数据占用的空间越来越大，备份时间越来越长（分库）。
- 应用的并发量太大（分库）。

垂直分表

表中的字段较多，一般将不常用的、 数据较大、长度较长的拆分到“扩展表“。一般情况加表的字段可能有几百列，此时是按照字段进行数竖直切。注意垂直分是列多的情况。

水平分表

单表的数据量太大。按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。这种情况是不建议使用的，因为数据量是逐渐增加的，当数据量增加到一定的程度还需要再进行切分。比较麻烦。

垂直分库

一个数据库的表太多。此时就会按照一定业务逻辑进行垂直切，比如用户相关的表放在一个数据库里，订单相关的表放在一个数据库里。注意此时不同的数据库应该存放在不同的服务器上，此时磁盘空间、内存、TPS等等都会得到解决。

水平分库

水平分库理论上切分起来是比较麻烦的，它是指将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

分库分表之后的问题：

联合查询困难，需要支持分布式事务，跨库join困难...

千万级大表的优化顺序：

1.优化sql和索引

2.上缓存，redis和memcached

3.主从复制，读写分离

4.分区表

5.分库分表，先垂直拆分，再水平拆分。