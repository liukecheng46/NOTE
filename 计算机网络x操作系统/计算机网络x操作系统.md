# 计算机网络x操作系统

udp的**丢包处理策略** **丢包重传（ARQ）**和**前向纠错（FEC）：信号在被送入传输信道之前预先按一定的算法进行编码处理，加入带有信号本身特征的冗码，在接收端按照相应算法对接收到的信号进行解码，从而找出在传输过程中产生的错误码并将其纠正的技术。即接收方自己纠错 如汉明码**

[数据链路层](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82)和[传输层](https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E5%B1%82)的错误纠正协议之一：**Automatic Repeat Request (ARQ)**

面试计网：

TCP五层模型：应用层、运输层、网络层、数据链路层和物理层

应用层：HTTP,DNS,FTP,SMTP，dhcp

传输层：TCP,UDP                            段（Segment）

网络层：IP,ARP，路由器                数据包（Packet）

链路层：交换机                              数据帧（Frame）

网络模型为什么要分层？

**各层之间相互独立进行了解耦，提高了整体灵活性，易于实现和维护**

1.**TCP与UDP的区别与应用场景**：

![Untitled](计算机网络x操作系统/Untitled.png)

HTTP,FTP,SMTP,SSH都是基于TCP协议

DNS,DHCP是基于UDP协议

TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：`FTP` 文件传输，`HTTP` / `HTTPS`

UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：包总量较少的通信，如 `DNS` 、`SNMP` 等。视频、音频等多媒体通信，广播通信（性能比完整性更重要，丢几个包无所谓）

![Untitled](计算机网络x操作系统/Untitled%201.png)

UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。UDP 协议真的非常简单，头部只有 `8` 个字节

- 目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。
- 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。
- 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计。

![Untitled](计算机网络x操作系统/Untitled%202.png)

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。

2**.TCP如何保证可靠的传输**：

（1）通过三次握手建立可靠链接

（2）**校验和**：会计算数据的校验和一并传输，接受的检验和对不上的话就会丢弃这个报文段并且不确认接收 **防止数据被篡改**

（3）**流量控制**：TCP利用滑动窗口实现流量控制，流量控制是为了控制发送方发送速率，保证接收方来得及接收。 **接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小**，从而影响发送方的发送速率，**避免接收方来不及接受导致的丢包问题**

（4）**拥塞控制**：当网络拥塞时，减少数据的发送。基于阻塞窗口采用慢开始、拥塞避免、快重传和快恢复，拥塞控制是一个全局的过程，涉及到所有的主机、路由器、以及降低网络相关的所有因素。流量控制往往指点对点通信量的控制。是端对端的问题

![Untitled](计算机网络x操作系统/Untitled%203.png)

**慢开始**：当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多MSS的数值。用这样的方法逐步增大发送方的拥塞窗口，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。

**拥塞避免**：当窗口大小大于慢开始门限（thresold）时，改用拥塞避免算法，每次加1，而不是加倍。

不论是慢开始还是拥塞避免阶段，**只要发送方判断网络出现阻塞（超时时间，即没有收到确认**），就把慢开始门限（thresold）设置为此时拥塞窗口的一半，重新把拥塞窗口设为1，执行慢开始（不执行快重传的情况）

**快重传**:

![Untitled](计算机网络x操作系统/Untitled%204.png)

当收到对一个报文的三个重复的 ACK 时，认为这个报文的下一个报文丢失了，进入快重传阶段，这要求接收方在收到一个失序的报文段后就立即发出重复确认而不要等到自己发送数据时捎带确认。

为什么是3个ack，因为如果只收到2个，一定是乱序造成的，3个其实也有可能是乱序造成的 [https://www.zhihu.com/question/21789252](https://www.zhihu.com/question/21789252)

![Untitled](计算机网络x操作系统/Untitled%205.png)

（5）**自动重传ARQ协议**：

- 停止等待ARQ：它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。
- 连续ARQ协议（回退N步）：停止等待的信道利用率太低，为了提高信道利用率，**发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去**，而不需要等待对方确认。**接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了**。

![Untitled](计算机网络x操作系统/Untitled%206.png)

![Untitled](计算机网络x操作系统/Untitled%207.png)

（1）凡是已经发送过的数据，在未收到确认之前，都必须暂时保留，以便在超时重传时使用。

（2）只有当发送方A收到了接收方的确认报文段时，发送方窗口才可以向前滑动几个序号。

（3）**当发送方A发送的数据经过一段时间没有收到确认（由超时计时器控制），就要使用回退N步协议，回到最后接收到确认号的地方，重新发送这部分数据。**

3.**TCP粘包现象原因和解决方法**
UDP按报文段发送，有保护消息边界，每一个消息都是独立的，而tcp是基于流的传输，流传输却把数据当作一串数据流，不认为数据是一个一个的消息。发送端需要等缓冲区满才发送出去，造成粘包。接收方不及时接收缓冲区的包，造成多个包粘包

（1）发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去(nagle算法)，这样接收方就收到了粘包数据。

（2）接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。

解法方法：本质就是无法像UDP一样区分数据包的边界，

1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。

2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。

3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。

4.**TCP的三次握手和四次挥手及相关问题**：[https://www.cnblogs.com/xiaolincoding/p/12638546.html](https://www.cnblogs.com/xiaolincoding/p/12638546.html)

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。

![Untitled](计算机网络x操作系统/Untitled%208.png)

    第三次握手客户端是可以携带数据的，但是前两次不行

 **为什么需要三次握手**：

三次握手才可以**阻止重复历史连接的初始化**（主要原因）：

![Untitled](计算机网络x操作系统/Untitled%209.png)

如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：

- 如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 `RST` 报文，以此中止历史连接；
- 如果不是历史连接，则第三次发送的报文是 `ACK` 报文，通信双方就会成功建立连接；

如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接，避免了资源浪费

三次握手才可以同步双方的初始序列号：

序列号是可靠传输的一个关键因素，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的；

所以当客户端发送携带「初始序列号」的 `SYN`报文的时候，需要服务端回一个 `ACK`应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

当某一端发现接受序列号和期望不一样时，就会返回RST报文，另一端接受后释放掉连接

**什么是连接时的SYN攻击？如何避免？**

假设攻击者短时间伪造不同 IP 地址的 `SYN`报文，服务端每接收到一个 `SYN`
 报文，就进入`SYN_RCVD`状态，但服务端发送出去的 `ACK + SYN`报文，无法得到未知 IP 主机的 `ACK`应答，久而久之就会**占满服务端的 SYN 接收队列（未连接队列）**，使得服务器不能为正常用户服务

修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。减少重发次数（5→2）增大连接数上限

**建立连接后的心跳检测（保活keep-alive机制）**：

TCP设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

**四次挥手流程：**

![Untitled](计算机网络x操作系统/Untitled%2010.png)

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。Close-wait状态的意义就是服务端还有数据要发送，这个时间内就是服务端发送完最后的数据
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

为什么挥手需要四次：

服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

为什么 TIME_WAIT 等待的时间是 2MSL：

MSL（Maximum Segment Lifetime），是指任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL`字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

说回原因：

第一是考虑丢包问题，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

第二个是防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

为什么需要TIME_WAIT状态：

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态

主要是两个原因：

- 防止具有相同「四元组」的「旧」数据包被收到；（防止本次tcp连接的历史包被下次在这个端口的新连接收到）
- 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭，如果TIME-WAIT没有或者过短，直接进入CLOSED状态，那么就不会接受服务端补发的FIN并返回ACK，服务端就会一直处于LAS_ACK状态无法关闭

TIME_WAIT 过多有什么危害？

对内存和端口资源的占用。导致新连接没法建立：高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上

可以配置Linux参数，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。

tcp握手挥手的异常及处理：[https://www.cnblogs.com/xiaolincoding/p/15131102.html](https://www.cnblogs.com/xiaolincoding/p/15131102.html)

### **Http和Https：**

Http协议是对客户端和服务器端之间数据之间实现可靠性的传输文字、图片、音频、视频等超文本数据的规范，格式简称为“超文本传输协议”

**为什么tcp是有状态 http用了tcp 但http是无状态的**：从本质上来说，二者没有可比性。HTTP协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次HTTP请求。HTTP会通过TCP建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，HTTP会立即将TCP连接断开（Http/1.1为了解决频繁的TCP断开连接，提出了**长连接**的通信方式，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态，减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载），这个过程是很短的。所以**HTTP连接是一种短连接，是一种无状态的连接**。无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议

200成功码

301永久重定向

302临时重定向

**400请求报文有错误**

403服务器禁止访问资源

404请求资源不存在

**500服务器内部错误**

502Bad GateWay服务器作为网关或代理时返回的错误

**503服务器当前忙，暂时无法响应**

常见字段：

Host 接收服务器域名

Connection: Keep-Alive 使用长连接，

*Content-Type： 返回什么类型的数据*

**http和tcp的keep-Alive区别**：

http的keep-alive是指HTTP 长连接，不再每次http请求都重新建立tcp连接，复用同一个，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。为了避免资源浪费的情况，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。

tcp的keep-alive是指TCP 保活机制，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

**https解决了什么问题**：[https://www.cnblogs.com/xiaolincoding/p/12442435.html](https://www.cnblogs.com/xiaolincoding/p/12442435.html)

在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程交换密钥，才可进入加密报文传输。

SSL/TLS握手建立安全连接过程：本质是通过非对称加密（证书里的公钥）进行后续对称密钥的交换（diff-hellman），非对称加密操作慢，所以第一次建立连接慢，后续就非常快，后续就用对称加密如AES。

CA证书包含了被认证实体的公钥和认证机构**CA的私钥的签名**，接收者获取CA的公钥通过CA私钥的签名来验证CA并信任他给的被认证实体的公钥（完成公钥的分发）

http 短连接，而且下一个请求要在上一个请求的响应来了才能发送，会导致**队头阻塞**

http/1.1提出了长连接，可以做到管道发送（同时发送多个http请求，但是没法实际解决队头阻塞，已经被抛弃），还增加了cache-control缓存策略（每次都去服务器拿资源，还是说用本地缓存），

http/2.0**基于HTTPS**，安全性有保障，会对**头进行压缩**：如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分。**报文格式**由文本形式改为二进制**，增加了数据传输效率，从而引入**多路复用**：**移除了 HTTP/1.1 中的串行请求，实现了真正的并行传输**，**不需要排队等待**，也就不会再出现「队头阻塞」问题，**降低了延迟，大幅度提高了连接的利用率**

http/3**由tcp协议改为udp，基于udp的quic协议实现了类似tcp的可靠性传输，减少握手时间。**引入前向纠错。每个数据包除了它本身的内容之外还包括了其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是带来的提升大于丢包导致的数据重传，因为数据重传将会消耗更多的时间(包括确认数据包丢失，请求重传，等待新数据包等步骤的时间消耗)。

例如：

- 我总共发送三个包，协议会算出这个三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。
- 当其中出现了非校验包丢失的情况，可以通过另外三个包计算出丢失的数据包的内容。
- 当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包，就不能使用纠错机制了，只能使用重传的方式了。

get和post

1.
get重点在从服务器上获取资源，post重点在向服务器发送数据；

**二**：
Get传输的数据量小，因为受URL长度限制，但效率较高；
Post可以传输大量数据，所以上传文件时只能用Post方式；

**三**：
get是不安全的，因为get请求发送数据是在URL上，是可见的，可能会泄露私密信息，如密码等；post是放在请求头部的，是安全的

****浏览器输入URL并回车的过程以及相关协议：****

（1）1. 浏览器先检查自身缓存中有没有被解析过的这个域名对应的ip地址，(如果有，解析结束。同时域名被缓存的时间也可通过TTL属性来设置。)

（2）在主机查询操作系统DNS缓存，也就是hosts文件里配置的。

（3）如果浏览器和系统缓存都没有，系统的 gethostname 函数就会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。

1. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
2. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
3. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
4. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
5. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
6. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
7. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

![Untitled](计算机网络x操作系统/Untitled%2011.png)

2、解析出IP地址后，根据IP地址和默认端口80和服务器建立连接，发送http请求并三次握手建立连接

3、服务器对浏览器的请求作出响应，并把对应的html文本发送给浏览器

4、释放TCP连接（四次挥手断开连接）

6、浏览器解析该HTML文本并显示内容

### **用到的协议**

- TCP:与服务器建立TCP连接
- IP: 建立TCP协议时，需要发送数据，发送数据在网络层使用IP协议
- OPSF: IP数据包在路由器之间，路由选择使用OPSF协议（路由寻址）
- ARP: 路由器在与服务器通信时，**需要将ip地址转换为MAC地址**，需要使用ARP协议
- HTTP:在TCP建立完成后，使用HTTP协议访问网页

ping的工作原理：

ICMP协议全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议。**

主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**

traceroute命令**故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。**

**cookies和session token区别：**

Http本身是无状态的，服务器无法判断用户身份，所以需要引入这些。

Cookie: 浏览器存储，第一次连接时服务器给浏览器发送它的Cookie，下次浏览器再请求时把Cookie一起发送，服务器通过Cookie来确认用户身份

Session：存储在服务器，会依赖Cookie来存储SessionId。第一次连接时服务器会生成Session并存储，再把对应的SessionId返回给浏览器(Set-Cookie：JSESSIONID=XXXXXXX)，浏览器会在cookie中存储SessionId，下次发送请求时服务器会根据Cookie里的Sessionid去取存的Session信息，确认用户身份。如果Cookie禁用了的话也可以直接在请求后加上  ?SessionId=XXX

cookie数据存放在客户端上，安全性较差，session数据放在服务器上，安全性相对更高

单个cookie保存的数据不能超过4K,session无此限制

session一定时间内保存在服务器上，当访问增多，占用服务器性能

Session的缺点是负载均衡会导致Session失效

引入Token：使用Session的话，客户端频繁向服务端请求数据，服务端需要频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否。因此引入Token简化这一步。

Token是服务端生成的一串字符串，保存了加密后的用户信息，第一次请求时服务器将生成的Token返回给客户端，以后只需要带上这个Token来请求数据即可，服务端有请求拦截器会通过算法验证Token是否合法（将数据库的验证转移到业务代码层面）。

Token过期时间很快，对于每个有效请求，服务器一般都会返回一个新的Token

java-jwt实现Token

分布式Session：使用外部的缓存设备来共享Session，避免单个服务器挂掉 spring-session-data-redis（JWT因为是无状态的，只需要加解密，所以默认就支持分布式）

`@EnableRedisHttpSession`

跨域请求（浏览器的同源策略）：非同源地址 Cookie LocalStroage等等都不能访问，一般通过配置Nginx代理避免

## **操作系统相关**：

**什么是系统调用**：

把进程在系统上的运行分为两个级别：

1. 用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。
2. 内核态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要**系统调用**了！ 也就是说在我们运行的用户程序中，**凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)**，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

进程和线程的区别？

从JVM来看的话，一个JVM就是一个进程。可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器**
、**虚拟机栈**和 **本地方法栈**
。

**进程间的通信方法**：

- **管道/匿名管道(Pipes)** ：用于具有亲缘关系的**父子进程间或者兄弟进程**之间的通信。
- **有名管道(Names Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
- **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
- **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。**
- **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
- **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。**这种方式需要依靠某种同步操作，如互斥锁和信号量等**。可以说这是最有用的进程间通信方式。
- **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。**套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点**，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

**线程间的通信方式**：

- **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
- **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
- **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

**进程间有什么调度算法**：

FIFO（先到先服务）

时间片轮转：

最短作业优先：

优先级调度：

多级反馈队列：是「时间片轮转调度」和「优先级调度」的综合和发展。前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程**。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

直接内存访问（DMA，Direct Memory Access）是一些计算机总线架构提供的功能，它能使数据从附加设备（如磁盘驱动器）直接发送到计算机主板的内存。减少了cpu中断进行IO的消耗

操作系统为了跟踪每个进程的活动状态，维护了一个`进程表`。在进程表的内部，列出了每个进程的状态以及每个进程使用的资源等。

上下文切换：于单核单线程 CPU 而言，在某一时刻只能执行一条 CPU 指令。上下文切换 (Context Switch) 是一种 **将 CPU 资源从一个进程分配给另一个进程的机制**。从用户角度看，计算机能够并行运行多个进程，这恰恰是操作系统通过快速上下文切换造成的结果。在切换的过程中，操作系统需要先存储当前进程的状态 (包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。

程序调用了printf(IO操作)会发生什么？回答：用户态到内核态的切换，进程上下文等，通过中断实现输出设备的输出

**虚拟内存**：当内存满了后，计算机可以执行操作是查看内存中最近未使用过的区域，然后将其复制到硬盘中对应的虚拟内存的物理地址。虚拟内存的实现建立在离散分配的内存管理方式的基础上。**可以使有限的物理内存运行一个比它大很多的程序**

虚拟地址是连续的，但它对应的物理地址不是连续的（每一页地址都是连续的地址范围。这些页被映射到物理内存，但不要求是连续的物理内存）

![Untitled](计算机网络x操作系统/Untitled%2012.png)

**分页**把内存空间划分为**大小相等且固定的块**，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，**因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。**访问分页系统中内存数据需要**两次的内存访问** (一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。

**分段**是把虚拟内存划分为多个独立的地址空间，每个地址空间可以动态增长，互不影响，段表中存放着段长度和段的起始地址，分段机制映射的是一片连续的物理内存。每个段可以单独进行控制，有助于保护和共享。 通过段号和偏移量访问内存。**一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的**。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。

在分段方法中，每次程序的运行都会被全部加载到虚拟内存中；而分页方法则不同，单位不是整个程序，而是某个“页”，一段虚拟地址空间组成的某一页映射到一段物理地址空间组成的某一页。它将少部分要运行的代码加载到虚拟内存中，通过映射在物理内存中运行，从而提高了物理内存的使用率

短页式先分段再分页

**分页分段的区别**：

- 分页对程序员是透明的，但是分段需要程序员显式划分每个段。
- 分页的地址空间是一维地址空间，分段是二维的。
- 页的大小不可变，段的大小可以动态改变。
- 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。
- 

缺页中断：在执行一条指令时，如果发现他要访问的页没有在内存中（存在位为0），**那么停止该指令的执行，并产生一个页不存在异常，对应的故障处理程序可通过从外存加载该页到内存的方法来排除故障**

**内存置换算法**：

*FIFO*

LRU：选择最长时间没有被访问的页面进行置换

LFU：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰

OPT：置换在「未来」最长时间不访问的页面，理想情况

**磁盘调度算法（电梯算法）**：

*FCFS*

最短寻道时间优先：可能导致饥饿

扫描算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向

**磁盘结构**

[https://www.nowcoder.com/discuss/588739?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack](https://www.nowcoder.com/discuss/588739?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack)

![Untitled](计算机网络x操作系统/Untitled%2013.png)

![Untitled](计算机网络x操作系统/Untitled%2014.png)

硬盘读取数据时，读写磁头沿径向移动，移到要读取的扇区所在磁道的上方，这段时间称为寻道时间(seek time)。因读写磁头的起始位置与目标位置之间的距离不同，寻道时间也不同。磁头到达指定磁道后，然后通过盘片的旋转，使得要读取的扇区转到读写磁头的下方，这段时间称为旋转延迟时间(rotational latencytime)。然后再读写数据，读写数据也需要时间，这段时间称为传输时间（transfer time）。

**Linux相关**

僵尸进程：**僵尸进程**是指完成执行（通过`[exit](https://zh.wikipedia.org/w/index.php?title=Exit_(Unix)&action=edit&redlink=1)`[系统调用](https://zh.wikipedia.org/wiki/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8)，或运行时发生[致命错误](https://zh.wikipedia.org/wiki/%E8%87%B4%E5%91%BD%E9%94%99%E8%AF%AF)或收到终止[信号](https://zh.wikipedia.org/wiki/%E4%BF%A1%E5%8F%B7_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6))所致），但在操作系统的进程表中仍然存在其[进程控制块](https://zh.wikipedia.org/wiki/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97)。进程长时间保持僵尸状态一般是错误的并导致[资源泄漏](https://zh.wikipedia.org/wiki/%E8%B5%84%E6%BA%90%E6%B3%84%E6%BC%8F)。僵尸进程通常发生在父子关系的进程中，父进程使用fork创建子进程，如果子进程退出，而父进程并没有调用waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。